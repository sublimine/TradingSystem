# AUDITOR√çA INSTITUCIONAL ‚Äì MANDATOS 1 A 5

**Proyecto**: SUBLIMINE TradingSystem
**Fecha**: 2025-11-13
**Auditor**: Sistema de Revisi√≥n Institucional
**Est√°ndar**: Model Risk + Market Risk + Internal Audit

**Advertencia**: Esta auditor√≠a identifica debilidades cr√≠ticas que podr√≠an causar p√©rdidas, degradaci√≥n operativa o rechazo en revisi√≥n institucional. Ninguna concesi√≥n. Solo hechos y acciones.

---

## MANDATO 1 ‚Äì AUDITOR√çA INSTITUCIONAL

**Alcance**: Infraestructura, correcci√≥n de 97 bugs (P0+P1+P2), scripts de integraci√≥n, entorno VPS.

**Estado actual**: COMPLETADO (correcciones), pero con **deficiencias institucionales graves** en gobernanza t√©cnica.

---

### RIESGOS / DEBILIDADES DETECTADAS

#### **P0 (CR√çTICO) ‚Äì Riesgos que pueden romper el sistema o causar p√©rdidas materiales**

**P0-001: Ausencia de estrategia formal de testing**

**Descripci√≥n**:
- 97 bugs corregidos sin evidencia de test suite que valide las correcciones.
- NO hay documentaci√≥n de:
  - Tests unitarios (unit tests).
  - Tests de integraci√≥n (integration tests).
  - Tests de regresi√≥n (regression tests).
- Riesgo: **Las correcciones de P0/P1/P2 pueden haber introducido nuevos bugs** (regresiones) que no se detectan hasta producci√≥n.

**Evidencia**:
- Archivos corregidos: `src/core/brain.py`, `src/core/risk_manager.py`, `src/core/position_manager.py`, `src/strategies/*.py`, `src/features/*.py`.
- NO existe carpeta `tests/` con cobertura sistem√°tica.
- NO hay CI/CD pipeline que ejecute tests autom√°ticamente en cada commit.

**Impacto**:
- **Muy alto**: Bug no detectado en `risk_manager.py` (ej: divisi√≥n por cero en c√°lculo de posici√≥n) puede causar:
  - √ìrdenes con tama√±o incorrecto (sobre-apalancamiento).
  - Crash del sistema en vivo.
  - P√©rdida material si se ejecutan trades con riesgo mal calculado.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-002: Falta de observabilidad institucional (logs, m√©tricas, alertas)**

**Descripci√≥n**:
- NO existe framework estructurado de logging.
- NO hay m√©tricas de salud del sistema (health checks).
- NO hay alertas autom√°ticas ante eventos cr√≠ticos:
  - P√©rdida diaria > X%.
  - Latencia de ejecuci√≥n > Y ms.
  - N√∫mero de rechazos de se√±al an√≥malo.
  - Ca√≠da de conexi√≥n a broker/MT5.

**Evidencia**:
- Archivos actuales usan `logger.warning()`, `logger.info()` de forma inconsistente.
- NO hay documento `OBSERVABILITY_RUNBOOK.md`.
- NO hay dashboard de m√©tricas en tiempo real.
- Scripts PowerShell (`monitor.ps1`, `start_trading.ps1`) NO tienen telemetr√≠a estructurada.

**Impacto**:
- **Muy alto**:
  - Sin logs estructurados, **imposible hacer post-mortem** de un fallo en producci√≥n.
  - Sin alertas, el sistema puede estar perdiendo dinero durante horas sin que nadie lo sepa.
  - Auditor√≠a interna rechazar√≠a sistema sin observabilidad m√≠nima.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-003: Riesgos de concurrency introducidos en correcciones P1**

**Descripci√≥n**:
- Correcciones P1-012 y P1-013 a√±adieron `threading.Lock()` en `decision_ledger.py` y `conflict_arbiter.py`.
- NO hay evidencia de:
  - An√°lisis de deadlock potential.
  - Tests de carga concurrente (stress tests).
  - Documentaci√≥n de orden de adquisici√≥n de locks.

**Evidencia**:
```python
# decision_ledger.py:12
self.lock = threading.Lock()

# conflict_arbiter.py
# (lock a√±adido pero sin documentaci√≥n de threading model)
```

**Impacto**:
- **Muy alto**:
  - Deadlock en producci√≥n ‚Üí sistema congelado.
  - M√∫ltiples estrategias generando se√±ales simult√°neas pueden causar contention excesiva.
  - Latencia impredecible en arbitraje de conflictos.

**Escenario concreto**:
```
Thread 1: Adquiere lock en decision_ledger ‚Üí espera lock en conflict_arbiter
Thread 2: Adquiere lock en conflict_arbiter ‚Üí espera lock en decision_ledger
‚Üí DEADLOCK
```

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-004: Validaciones introducidas en P2 pueden bloquear sistema en condiciones edge**

**Descripci√≥n**:
- Correcciones P2 a√±adieron validaciones estrictas:
  - P2-020: `abs(denominator) < 1e-6` en lugar de `== 0`.
  - P2-023: `if sig is None: raise ValueError()`.
  - P2-024: `if total_capital < 0: raise ValueError()`.
- Validaciones correctas **PERO**:
  - NO hay manejo de excepciones en nivel superior.
  - NO hay fallback/degraded mode si validaci√≥n falla.

**Evidencia**:
```python
# portfolio_manager.py
if sig is None:
    raise ValueError("Invalid signal (None) in executions")
# ¬øQu√© pasa si esto se lanza en producci√≥n? ¬øCrash total o log + skip?
```

**Impacto**:
- **Alto**: Una se√±al `None` por bug upstream causa:
  - Crash de `portfolio_manager`.
  - Stop completo del sistema.
  - NO hay circuit breaker que capture excepci√≥n y contin√∫e operando con otras se√±ales.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

#### **P1 (IMPORTANTE) ‚Äì Degrada calidad institucional, no mata el sistema inmediatamente**

**P1-001: Ausencia de pol√≠tica de versionado y tagging institucional**

**Descripci√≥n**:
- Commits tienen mensajes descriptivos (correcto).
- NO hay:
  - Tags sem√°nticos (v1.0.0, v1.1.0, etc.).
  - Releases formales.
  - CHANGELOG estructurado.
  - Convenci√≥n de versiones (semantic versioning).

**Evidencia**:
- Historial de commits: `d26bba6`, `6484be8`, `d71f196` (SHAs, no tags).
- NO existe `CHANGELOG.md`.

**Impacto**:
- **Medio**:
  - Imposible rastrear qu√© versi√≥n exacta est√° en producci√≥n.
  - Rollback complicado sin tags claros.
  - Auditor√≠a interna requiere versionado formal.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-002: Scripts PowerShell sin validaci√≥n ni error handling robusto**

**Descripci√≥n**:
- Scripts `INTEGRATE_VPS.ps1`, `monitor.ps1`, `start_trading.ps1`, `sync.ps1`:
  - Normalizados (line endings LF).
  - PERO: NO hay evidencia de:
    - Manejo de errores (try/catch).
    - Validaci√≥n de precondiciones (ej: VPS alcanzable antes de sync).
    - Logs estructurados de ejecuci√≥n.

**Evidencia**:
- Archivos `.ps1` presentes en repo.
- Commit `chore: Normalizar line endings en archivos PowerShell`.
- NO hay `docs/SCRIPTS_USAGE.md` con runbook.

**Impacto**:
- **Medio**:
  - Script falla silenciosamente ‚Üí datos no sincronizados ‚Üí decisiones con datos stale.
  - Dificulta troubleshooting en entorno VPS.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-003: Falta de runbooks operacionales**

**Descripci√≥n**:
- NO existe documentaci√≥n de:
  - C√≥mo arrancar el sistema en producci√≥n.
  - C√≥mo hacer rollback ante fallo.
  - C√≥mo diagnosticar latencia elevada.
  - C√≥mo responder a p√©rdida > X% diaria.

**Evidencia**:
- √önico documento operacional: `docs/REPO_GOVERNANCE.md` (branching/PR, NO operaciones).
- Falta: `OPERATIONAL_RUNBOOK.md`, `INCIDENT_RESPONSE.md`.

**Impacto**:
- **Medio**:
  - Ante incidente, respuesta lenta por falta de procedimientos documentados.
  - Onboarding de nuevo operador/dev lleva mucho tiempo.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-004: Ausencia de an√°lisis de cobertura de correcciones P0/P1/P2**

**Descripci√≥n**:
- 97 bugs corregidos:
  - 12 P0 (cr√≠ticos).
  - 27 P1 (importantes).
  - 26 P2 (menores).
- NO hay m√©tricas de:
  - Qu√© % de c√≥digo fue tocado.
  - Qu√© √°reas tienen mayor densidad de bugs (hotspots).
  - Qu√© estrategias/m√≥dulos son m√°s fr√°giles.

**Evidencia**:
- Auditor√≠as `AUDIT_P2_BUGS_20251113.md` existen (correcto).
- PERO: NO hay an√°lisis estad√≠stico tipo:
  - "5 bugs en `order_flow.py` ‚Üí m√≥dulo de alto riesgo".
  - "Estrategia `liquidity_sweep` tiene 3 bugs ‚Üí revisar dise√±o completo".

**Impacto**:
- **Medio**:
  - NO se priorizan m√≥dulos para refactoring profundo.
  - Riesgo de seguir corrigiendo s√≠ntomas en lugar de causas ra√≠z.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-005: Falta de integraci√≥n continua (CI/CD)**

**Descripci√≥n**:
- NO hay pipeline CI/CD que:
  - Ejecute tests autom√°ticamente en cada push.
  - Valide linting/formatting.
  - Genere builds de artefactos.
  - Despliegue a entorno staging antes de producci√≥n.

**Evidencia**:
- NO existe `.github/workflows/ci.yml` o similar.
- NO hay integraci√≥n con GitHub Actions, GitLab CI, Jenkins, etc.

**Impacto**:
- **Medio**:
  - Bugs llegan a producci√≥n que podr√≠an haberse detectado en CI.
  - Despliegues manuales son lentos y propensos a error humano.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

#### **P2 (MENOR) ‚Äì Calidad de c√≥digo, naming, documentaci√≥n**

**P2-001: Inconsistencia en nomenclatura de archivos y funciones**

**Descripci√≥n**:
- Mix de estilos:
  - `snake_case` en algunos archivos.
  - `camelCase` en otros.
  - Nombres poco descriptivos (ej: `calculate_score()` sin contexto de qu√© score).

**Evidencia**:
- `src/features/technical_indicators.py`: funci√≥n `detect_divergence()` (stub).
- `src/core/brain.py`: funci√≥n `arbitrate()` sin docstring completo.

**Impacto**:
- **Bajo**: Dificulta lectura de c√≥digo, pero NO causa fallos.

**Severidad**: **P2 ‚Äì MENOR**

---

**P2-002: Falta de docstrings completos en funciones cr√≠ticas**

**Descripci√≥n**:
- Muchas funciones carecen de:
  - Descripci√≥n completa de par√°metros.
  - Tipos de retorno.
  - Excepciones lanzadas.

**Evidencia**:
- Correcciones P2 a√±adieron comentarios, pero NO docstrings formales tipo:
```python
def calculate_quality_score(signal: Signal) -> float:
    """
    Calcula quality score de se√±al.

    Args:
        signal: Se√±al de estrategia con entry, direction, etc.

    Returns:
        Score [0.0, 1.0]

    Raises:
        ValueError: Si signal.entry_price <= 0
    """
```

**Impacto**:
- **Bajo**: Dificulta mantenimiento, NO causa fallos directos.

**Severidad**: **P2 ‚Äì MENOR**

---

**P2-003: Thresholds hardcodeados sin configuraci√≥n centralizada**

**Descripci√≥n**:
- Thresholds documentados en c√≥digo (correcto tras P2), pero:
  - NO hay archivo de configuraci√≥n centralizado tipo `config/thresholds.yaml`.
  - Cambiar threshold requiere editar c√≥digo Python.

**Evidencia**:
- `src/core/brain.py`: `min_arbitration_score = 0.65` hardcodeado.
- `src/features/order_flow.py`: `vpin_threshold = 0.50` hardcodeado.

**Impacto**:
- **Bajo**: Cambiar thresholds es lento, pero NO rompe sistema.

**Severidad**: **P2 ‚Äì MENOR**

---

### RESUMEN DE RIESGOS MANDATO 1

| Severidad | Cantidad | Cr√≠ticos destacados |
|-----------|----------|---------------------|
| **P0 (CR√çTICO)** | 4 | Testing ausente, Observabilidad nula, Deadlocks potenciales, Validaciones sin fallback |
| **P1 (IMPORTANTE)** | 5 | Versionado, Scripts sin error handling, Runbooks ausentes, Sin CI/CD |
| **P2 (MENOR)** | 3 | Naming inconsistente, Docstrings incompletos, Thresholds hardcodeados |
| **TOTAL** | **12** | **4 P0 requieren acci√≥n inmediata** |

---

### MEJORAS INSTITUCIONALES RECOMENDADAS

#### **Acci√≥n M1-001: Crear estrategia formal de testing**

**Qu√© hacer**:
1. Crear documento `docs/TESTING_STRATEGY.md` con:
   - Matriz de cobertura m√≠nima:
     - Core: 80% coverage.
     - Strategies: 70% coverage.
     - Features: 60% coverage.
   - Tipos de tests:
     - Unit tests: funciones individuales.
     - Integration tests: flujo completo (se√±al ‚Üí QualityScorer ‚Üí RiskAllocator ‚Üí orden).
     - Regression tests: validar que bugs corregidos NO reaparecen.
   - Framework: `pytest` + `pytest-cov`.

2. Crear estructura `tests/`:
```
tests/
  unit/
    test_brain.py
    test_risk_manager.py
    test_position_manager.py
  integration/
    test_signal_to_execution_flow.py
  regression/
    test_p0_bugs_fixed.py
    test_p1_bugs_fixed.py
```

3. Implementar tests cr√≠ticos PRIMERO:
   - Test de divisi√≥n por cero en `risk_manager.py`.
   - Test de concurrency en `decision_ledger.py` (simular 10 threads).
   - Test de validaci√≥n de se√±al `None` en `portfolio_manager.py`.

**Impacto**: **Muy alto** ‚Äì Previene regresiones, detecta bugs antes de producci√≥n.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M1-002: Implementar observabilidad institucional**

**Qu√© hacer**:
1. Crear documento `docs/OBSERVABILITY_RUNBOOK.md` con:
   - Pol√≠ticas de logging:
     - Niveles: DEBUG, INFO, WARNING, ERROR, CRITICAL.
     - Formato estructurado: JSON logs con campos:
       - `timestamp`, `level`, `module`, `event`, `data`.
   - M√©tricas a capturar (m√≠nimo):
     - Latencia de ejecuci√≥n de se√±al (p50, p95, p99).
     - N√∫mero de se√±ales generadas/rechazadas por minuto.
     - Drawdown actual vs l√≠mite.
     - Uptime del sistema.
   - Alertas obligatorias:
     - P√©rdida diaria > 5%.
     - Latencia > 100ms en decisi√≥n cr√≠tica.
     - Conexi√≥n a broker ca√≠da.
     - Sistema sin se√±ales durante > 1 hora (posible freeze).

2. Implementar logging estructurado:
```python
import structlog

logger = structlog.get_logger()

logger.info(
    "signal_generated",
    strategy="momentum_quality",
    symbol="EURUSD",
    direction="LONG",
    quality_score=0.87
)
```

3. Integrar stack de observabilidad:
   - Logs: `structlog` ‚Üí archivo JSON.
   - M√©tricas: `prometheus_client` ‚Üí Prometheus ‚Üí Grafana.
   - Alertas: Prometheus Alertmanager ‚Üí Email/Telegram.

4. Dashboard m√≠nimo en Grafana:
   - Panel 1: PnL acumulado.
   - Panel 2: N√∫mero de trades ejecutados vs rechazados.
   - Panel 3: Latencia p95 de decisi√≥n.
   - Panel 4: Quality score distribution.

**Impacto**: **Muy alto** ‚Äì Permite detectar problemas en tiempo real, hacer post-mortems, pasar auditor√≠as.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M1-003: An√°lisis y mitigaci√≥n de riesgos de concurrency**

**Qu√© hacer**:
1. Documentar threading model en `docs/CONCURRENCY_MODEL.md`:
   - Qu√© componentes usan locks.
   - Orden de adquisici√≥n de locks (para evitar deadlocks).
   - Timeout en adquisici√≥n de locks.

2. Regla estricta de orden de locks:
```python
# SIEMPRE adquirir locks en este orden:
# 1. decision_ledger.lock
# 2. conflict_arbiter.lock
# 3. portfolio_manager.lock
# NUNCA al rev√©s.
```

3. A√±adir timeouts:
```python
if not self.lock.acquire(timeout=1.0):
    logger.error("lock_timeout", component="decision_ledger")
    raise TimeoutError("No se pudo adquirir lock en 1s")
```

4. Implementar tests de stress concurrente:
```python
def test_concurrent_signal_processing():
    threads = []
    for i in range(50):
        t = threading.Thread(target=process_signal, args=(signal_i,))
        threads.append(t)
        t.start()

    for t in threads:
        t.join(timeout=5.0)

    assert no_deadlock_occurred()
```

**Impacto**: **Muy alto** ‚Äì Previene deadlocks en producci√≥n.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M1-004: A√±adir fallback/degraded mode en validaciones**

**Qu√© hacer**:
1. Envolver validaciones cr√≠ticas con manejo de excepciones:
```python
# portfolio_manager.py
try:
    if sig is None:
        raise ValueError("Invalid signal (None)")
except ValueError as e:
    logger.error("validation_failed", error=str(e), signal_id=sig_id)
    # NO crash: registrar error y continuar con siguiente se√±al
    continue
```

2. Implementar circuit breaker:
```python
if error_count_last_minute > 10:
    logger.critical("circuit_breaker_triggered")
    # Pausa procesamiento de se√±ales durante 1 minuto
    time.sleep(60)
```

3. Definir modos operacionales:
   - **NORMAL**: Todas las validaciones activas.
   - **DEGRADED**: Validaciones relajadas, logs agresivos.
   - **EMERGENCY_STOP**: No se procesan se√±ales nuevas.

**Impacto**: **Alto** ‚Äì Sistema m√°s robusto ante condiciones edge.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M1-005: Implementar versionado sem√°ntico y tagging**

**Qu√© hacer**:
1. Crear `VERSIONING_POLICY.md`:
   - Usar Semantic Versioning (semver): `MAJOR.MINOR.PATCH`.
   - Ejemplos:
     - `v1.0.0`: Release inicial post-correcci√≥n 97 bugs.
     - `v1.1.0`: A√±adir Risk Engine implementado.
     - `v1.1.1`: Bugfix menor en VPIN calculation.

2. Crear tags en git:
```bash
git tag -a v1.0.0 -m "Release 1.0.0: 97 bugs corregidos, base institucional"
git push origin v1.0.0
```

3. Mantener `CHANGELOG.md`:
```markdown
# Changelog

## [1.0.0] - 2025-11-13
### Fixed
- P0-001: Divisi√≥n por cero en risk_manager.py
- P1-011: Race condition en decision_ledger.py
...

### Added
- Thresholds documentados en brain.py, order_flow.py
```

**Impacto**: **Medio** ‚Äì Mejora trazabilidad, facilita rollbacks.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M1-006: Crear runbooks operacionales**

**Qu√© hacer**:
1. Crear `docs/OPERATIONAL_RUNBOOK.md` con secciones:
   - **Startup**: C√≥mo arrancar sistema en producci√≥n.
   - **Shutdown**: C√≥mo detener sistema sin p√©rdida de datos.
   - **Rollback**: C√≥mo volver a versi√≥n anterior.
   - **Troubleshooting com√∫n**:
     - Latencia alta ‚Üí revisar logs de microestructura.
     - Se√±ales rechazadas en masa ‚Üí verificar Quality Score thresholds.
     - Conexi√≥n MT5 ca√≠da ‚Üí reiniciar connector.

2. Crear `docs/INCIDENT_RESPONSE.md`:
   - Niveles de severidad de incidentes:
     - **SEV1 (CR√çTICO)**: P√©rdida > 10% diaria, sistema ca√≠do.
     - **SEV2 (ALTO)**: P√©rdida > 5%, latencia > 500ms.
     - **SEV3 (MEDIO)**: Comportamiento an√≥malo sin p√©rdida material.
   - Procedimientos:
     - SEV1 ‚Üí EMERGENCY_STOP inmediato + an√°lisis post-mortem.
     - SEV2 ‚Üí Investigaci√≥n en caliente, posible degraded mode.
     - SEV3 ‚Üí Log + revisi√≥n diferida.

**Impacto**: **Medio** ‚Äì Reduce tiempo de respuesta ante incidentes.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M1-007: Validar y endurecer scripts PowerShell**

**Qu√© hacer**:
1. A√±adir error handling a todos los scripts `.ps1`:
```powershell
# INTEGRATE_VPS.ps1
try {
    # ... l√≥gica de sync ...
} catch {
    Write-Error "Sync failed: $_"
    Exit 1
}
```

2. Validaciones previas:
```powershell
# Verificar que VPS es alcanzable
if (-not (Test-Connection -ComputerName $VPS_IP -Count 1 -Quiet)) {
    Write-Error "VPS not reachable"
    Exit 1
}
```

3. Logging estructurado:
```powershell
function Log-Info($message) {
    $timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
    Write-Output "$timestamp [INFO] $message" | Out-File -Append sync.log
}
```

4. Crear `docs/SCRIPTS_USAGE.md` con documentaci√≥n de cada script.

**Impacto**: **Medio** ‚Äì Scripts m√°s robustos, menos fallos silenciosos.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M1-008: Implementar CI/CD pipeline**

**Qu√© hacer**:
1. Crear `.github/workflows/ci.yml`:
```yaml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python 3.10
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest tests/ --cov=src --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v2
```

2. Gates de calidad:
   - Coverage m√≠nimo: 70%.
   - Todos los tests deben pasar.
   - Linting con `flake8` o `ruff`.

3. Staging deployment autom√°tico:
   - En merge a branch `ALGORITMO_INSTITUCIONAL_SUBLIMINE`, deploy autom√°tico a VPS staging.
   - Smoke tests en staging antes de producci√≥n.

**Impacto**: **Medio-Alto** ‚Äì Detecta problemas antes de merge, automatiza despliegues.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M1-009: An√°lisis de hotspots de bugs**

**Qu√© hacer**:
1. Crear script de an√°lisis:
```python
# tools/bug_hotspot_analysis.py
import pandas as pd

bugs = [
    {'file': 'order_flow.py', 'severity': 'P1', 'count': 5},
    {'file': 'liquidity_sweep.py', 'severity': 'P2', 'count': 3},
    # ... todos los bugs ...
]

df = pd.DataFrame(bugs)
hotspots = df.groupby('file').agg({'count': 'sum', 'severity': 'min'})
print("Top 5 archivos con m√°s bugs:")
print(hotspots.sort_values('count', ascending=False).head(5))
```

2. Generar `docs/BUG_HOTSPOT_REPORT.md` con:
   - Top 10 archivos con m√°s bugs.
   - Estrategias con mayor densidad de bugs.
   - Recomendaci√≥n: refactoring completo de archivos con >5 bugs.

3. Priorizar refactoring:
   - Archivos con ‚â•5 bugs ‚Üí candidatos a reescritura completa.
   - Estrategias "broken" (3 en total) ‚Üí no refactorizar, eliminar y reescribir desde cero.

**Impacto**: **Medio** ‚Äì Identifica √°reas de alto riesgo para intervenci√≥n profunda.

**Prioridad**: **P1 ‚Äì MEDIA**

---

#### **Acci√≥n M1-010: Centralizar configuraci√≥n de thresholds**

**Qu√© hacer**:
1. Crear `config/thresholds.yaml`:
```yaml
brain:
  min_arbitration_score: 0.65
  vpin_threshold_low: 0.30
  vpin_threshold_high: 0.50

order_flow:
  vpin_bucket_volume:
    EURUSD: 100000
    GBPUSD: 80000
    XAUUSD: 50000
```

2. Cargar config en runtime:
```python
import yaml

with open('config/thresholds.yaml') as f:
    config = yaml.safe_load(f)

min_arbitration_score = config['brain']['min_arbitration_score']
```

3. Validaci√≥n de config al startup:
```python
def validate_config(config):
    assert 0.0 <= config['brain']['min_arbitration_score'] <= 1.0
    # ... m√°s validaciones ...
```

**Impacto**: **Bajo** ‚Äì Facilita ajustes de thresholds sin tocar c√≥digo.

**Prioridad**: **P2 ‚Äì BAJA**

---

### PLAN DE ACCI√ìN PRIORIZADO ‚Äì MANDATO 1

**Fase inmediata (Semana 1)**:
1. **M1-001**: Crear `TESTING_STRATEGY.md` + estructura `tests/` + tests cr√≠ticos P0.
2. **M1-002**: Implementar logging estructurado + alertas m√≠nimas.
3. **M1-003**: Documentar threading model + a√±adir timeouts en locks.
4. **M1-004**: A√±adir fallback en validaciones + circuit breaker b√°sico.

**Fase corto plazo (Semana 2-3)**:
5. **M1-005**: Implementar versionado sem√°ntico + `CHANGELOG.md`.
6. **M1-006**: Crear runbooks operacionales e incident response.
7. **M1-007**: Endurecer scripts PowerShell con error handling.
8. **M1-008**: Configurar CI/CD b√°sico con GitHub Actions.

**Fase medio plazo (Mes 1)**:
9. **M1-009**: An√°lisis de hotspots + priorizaci√≥n de refactoring.
10. **M1-010**: Centralizar thresholds en `config/thresholds.yaml`.

---

### VEREDICTO FINAL ‚Äì MANDATO 1

**Estado**: ‚ö†Ô∏è **COMPLETADO CON DEFICIENCIAS CR√çTICAS**

**Logros**:
- ‚úÖ 97 bugs corregidos (P0+P1+P2).
- ‚úÖ C√≥digo base funcional.
- ‚úÖ Documentaci√≥n de thresholds a√±adida.

**Fallas institucionales**:
- ‚ùå **Testing ausente** ‚Üí riesgo P0 de regresiones.
- ‚ùå **Observabilidad nula** ‚Üí imposible operar en producci√≥n con seguridad.
- ‚ùå **Concurrency sin an√°lisis** ‚Üí riesgo P0 de deadlocks.
- ‚ùå **Validaciones sin fallback** ‚Üí riesgo P0 de crash total.

**Recomendaci√≥n**:
**NO DESPLEGAR A PRODUCCI√ìN** hasta completar:
- M1-001 (Testing).
- M1-002 (Observabilidad).
- M1-003 (Concurrency an√°lisis).
- M1-004 (Fallback en validaciones).

**Aprobaci√≥n condicional**: Sistema puede pasar a Mandato 2 (Estrategias) SOLO si se ejecuta plan de acci√≥n inmediato en paralelo.

---

**FIN AUDITOR√çA MANDATO 1**

---

## MANDATO 2 ‚Äì AUDITOR√çA INSTITUCIONAL

**Alcance**: Portfolio de 24 estrategias, clasificaci√≥n broken/hybrid/approved, integraci√≥n con Risk Engine y Microestructura.

**Estado actual**: PENDIENTE DE CIRUG√çA - **Zoo de estrategias sin gobernanza, solapamientos masivos, falta de cat√°logo institucional**.

---

### RIESGOS / DEBILIDADES DETECTADAS

#### **P0 (CR√çTICO) ‚Äì Riesgos que pueden causar p√©rdidas materiales o degradaci√≥n severa**

**P0-005: Ausencia total de cat√°logo institucional de estrategias**

**Descripci√≥n**:
- 24 estrategias identificadas en `src/strategies/`:
  - `momentum_quality.py`
  - `liquidity_sweep.py`
  - `order_block_institutional.py`
  - `breakout_volume_confirmation.py`
  - `mean_reversion_statistical.py`
  - `vpin_reversal_extreme.py`
  - `order_flow_toxicity.py`
  - `ofi_refinement.py`
  - `spoofing_detection_l2.py`
  - `iceberg_detection.py`
  - `nfp_news_event_handler.py`
  - `htf_ltf_liquidity.py`
  - `fvg_institutional.py`
  - `idp_inducement_distribution.py`
  - `footprint_orderflow_clusters.py`
  - `kalman_pairs_trading.py`
  - `statistical_arbitrage_johansen.py`
  - `correlation_divergence.py`
  - `correlation_cascade_detection.py`
  - `volatility_regime_adaptation.py`
  - `fractal_market_structure.py`
  - `topological_data_analysis_regime.py`
  - `crisis_mode_volatility_spike.py`
  - `calendar_arbitrage_flows.py`

- **NO existe documento `STRATEGY_CATALOG.md`** con:
  - Nombre formal.
  - Tipo (momentum, mean reversion, liquidity, news, arbitrage, etc.).
  - Universo de s√≠mbolos aplicable (FX, commodities, crypto, indices).
  - Horizonte de holding esperado (minutos, horas, d√≠as).
  - M√©tricas objetivo: Sharpe, hit rate, max DD.
  - Estado (experimental, pilot, production, degraded, retired).

**Evidencia**:
- 24 archivos `.py` en `src/strategies/`.
- NO existe `docs/STRATEGY_CATALOG.md`.
- NO hay archivo central que liste qu√© estrategias est√°n activas vs desactivadas.
- `brain.py` tiene `fit_matrix` hardcodeado con nombres de estrategias sin documentaci√≥n de estado.

**Impacto**:
- **Muy alto**:
  - **Imposible saber qu√© estrategias est√°n en producci√≥n** vs experimentales.
  - **Riesgo de activar estrategias "broken"** sin querer.
  - **Auditor√≠a interna rechazar√≠a sistema** sin inventario formal de estrategias.
  - **No se puede evaluar exposici√≥n por tipo de estrategia** (ej: "¬øcu√°nto riesgo tenemos en momentum vs mean reversion?").

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-006: Factor crowding interno masivo (m√∫ltiples estrategias = misma idea)**

**Descripci√≥n**:
- Solapamiento brutal entre estrategias:
  - **Order Flow**: `order_flow_toxicity.py`, `ofi_refinement.py`, `footprint_orderflow_clusters.py` ‚Üí 3 estrategias mirando OFI/VPIN.
  - **Liquidity**: `liquidity_sweep.py`, `htf_ltf_liquidity.py`, `iceberg_detection.py`, `spoofing_detection_l2.py` ‚Üí 4 estrategias mirando liquidez/Level 2.
  - **Order Blocks**: `order_block_institutional.py`, `fvg_institutional.py`, `idp_inducement_distribution.py` ‚Üí 3 estrategias con conceptos ICT/SMC.
  - **Correlaci√≥n**: `correlation_divergence.py`, `correlation_cascade_detection.py` ‚Üí 2 estrategias casi id√©nticas.
  - **Pairs Trading**: `kalman_pairs_trading.py`, `statistical_arbitrage_johansen.py` ‚Üí 2 estrategias de stat arb.

- **Riesgo**: Si 3-4 estrategias disparan se√±ales al mismo tiempo porque miran el mismo edge:
  - **Sobre-exposici√≥n** a un solo factor (ej: "order flow positivo").
  - **Conteo triple del mismo riesgo** ‚Üí rompe l√≠mite de 2% por idea si cada estrategia pide 1.5%.
  - **Correlaci√≥n entre estrategias = 1.0** ‚Üí diversificaci√≥n cero.

**Evidencia**:
- Lectura de c√≥digo:
  - `order_flow_toxicity.py` usa VPIN + OFI.
  - `ofi_refinement.py` usa OFI + delta.
  - `footprint_orderflow_clusters.py` usa footprint (que tambi√©n es order flow).
- NO hay matriz de correlaci√≥n entre estrategias.
- NO hay an√°lisis de overlap de features.

**Impacto**:
- **Muy alto**:
  - **Drawdown amplificado**: Si el factor subyacente falla, todas las estrategias pierden juntas.
  - **ExposureManager puede NO detectar** que 4 estrategias = 1 sola idea.
  - **Sharpe del portfolio se degrada** por falta de diversificaci√≥n real.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-007: Clasificaci√≥n "broken/hybrid/approved" sin criterios documentados**

**Descripci√≥n**:
- Usuario mencion√≥:
  - 13 "aprobadas".
  - 8 "hybrid".
  - 3 "broken".
- **NO existe documento que defina**:
  - ¬øQu√© hace que una estrategia sea "aprobada"?
    - ¬øSharpe > X?
    - ¬øWin rate > Y%?
    - ¬øBacktest en N meses de datos?
  - ¬øQu√© hace que una estrategia sea "hybrid"?
  - ¬øQu√© hace que una estrategia sea "broken"?
  - ¬øCu√°ndo una estrategia pasa de "experimental" ‚Üí "production"?
  - ¬øCu√°ndo una estrategia se degrada y se retira?

**Evidencia**:
- NO existe `docs/STRATEGY_LIFECYCLE_POLICY.md`.
- NO hay m√©tricas de promoci√≥n/degradaci√≥n.
- NO hay proceso formal de aprobaci√≥n.

**Impacto**:
- **Muy alto**:
  - **Estrategias "aprobadas" pueden estar rotas** sin que nadie lo detecte.
  - **Estrategias "broken" pueden activarse** por error.
  - **Sin criterios objetivos, decisiones son subjetivas** ‚Üí inaceptable para auditor√≠a.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-008: Estrategias usan conceptos SMC/ICT sin formalizaci√≥n cuantitativa rigurosa**

**Descripci√≥n**:
- Varias estrategias usan terminolog√≠a SMC/ICT:
  - `order_block_institutional.py`: "order blocks", "displacement".
  - `fvg_institutional.py`: "Fair Value Gap".
  - `idp_inducement_distribution.py`: "Inducement, Distribution, Price delivery" (conceptos SMC puros).
  - `htf_ltf_liquidity.py`: "liquidity sweeps".

- Aunque el c√≥digo intenta formalizarlos (ej: `order_block_institutional.py` cita papers de Hasbrouck, Easley):
  - **Riesgo de subjetividad residual**: T√©rminos como "displacement" o "FVG" pueden interpretarse de m√∫ltiples formas.
  - **No hay backtests publicados** que validen que estos conceptos funcionan cuantitativamente.
  - **Olor a retail camuflado**: Auditor√≠a institucional cuestionar√≠a si esto es market microstructure real o SMC con paper citations.

**Evidencia**:
```python
# order_block_institutional.py:4
"""
üèÜ REAL INSTITUTIONAL IMPLEMENTATION - NO RETAIL DISPLACEMENT GARBAGE
...
```
- Comentarios agresivos contra retail, pero definiciones a√∫n dependen de "displacement", "OFI absorption", conceptos que necesitan validaci√≥n emp√≠rica.

**Impacto**:
- **Alto**:
  - **Model Risk rechazar√≠a** estrategias sin validaci√≥n emp√≠rica robusta.
  - **Riesgo de overfitting** a patrones que no se replican en vivo.
  - **Credibilidad del sistema degradada** si auditor detecta terminolog√≠a retail.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

#### **P1 (IMPORTANTE) ‚Äì Degrada calidad institucional**

**P1-006: Falta de integraci√≥n expl√≠cita de estrategias con MANDATO 4 (QualityScorer) y MANDATO 5 (Microestructura/Multiframe)**

**Descripci√≥n**:
- Estrategias implementadas, pero:
  - **NO declaran expl√≠citamente**:
    - Qu√© features de microestructura usan (VPIN, OFI, depth, spoofing).
    - Qu√© dependencia tienen del MultiFrameContext (HTF/MTF/LTF).
    - Qu√© peso estructural esperan en QualityScorer (v√≠a pedigree).

- Ejemplo: `momentum_quality.py`:
  - Usa `vpin_clean_max`, `vpin_toxic_min`.
  - PERO: NO declara formalmente dependency en `MicrostructureEngine`.
  - ¬øQu√© pasa si microstructure data est√° degradada?

**Evidencia**:
- Archivos de estrategias NO tienen secci√≥n tipo:
```python
DEPENDENCIES = {
    'microstructure': ['vpin', 'ofi'],
    'multiframe': ['htf_trend', 'mtf_zones'],
    'min_data_health_score': 0.70,
}
```

**Impacto**:
- **Medio**:
  - **Debugging complicado**: Si estrategia falla, no est√° claro qu√© componente upstream caus√≥ el problema.
  - **Integraci√≥n fr√°gil**: Cambios en MicrostructureEngine pueden romper estrategias sin que nadie lo sepa.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-007: Ausencia de backtests documentados con m√©tricas institucionales**

**Descripci√≥n**:
- 24 estrategias, CERO backtests documentados con:
  - Sharpe ratio.
  - Max drawdown.
  - Win rate.
  - Profit factor.
  - Per√≠odo de backtest (ej: 2020-2024).
  - Out-of-sample validation.

**Evidencia**:
- NO existe `docs/BACKTEST_RESULTS.md`.
- NO hay carpeta `backtests/` con resultados archivados.
- Algunos archivos tienen comentarios tipo:
```python
# order_block_institutional.py:56
Win Rate: 70-77% (institutional grade with order flow confirmation)
```
- PERO: Sin evidencia emp√≠rica, esto es marketing, no validaci√≥n.

**Impacto**:
- **Medio**:
  - **Imposible evaluar qu√© estrategias funcionan** sin backtests.
  - **Model Risk rechazar√≠a** estrategias sin validaci√≥n emp√≠rica.
  - **Riesgo de desplegar estrategias que pierden dinero** en vivo.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-008: Hardcoded thresholds en estrategias sin proceso de calibraci√≥n**

**Descripci√≥n**:
- Todas las estrategias tienen thresholds hardcodeados:
  - `momentum_quality.py`: `price_threshold=0.30`, `volume_threshold=1.40`, `vpin_clean_max=0.30`.
  - `liquidity_sweep.py`: `penetration_min=3`, `penetration_max=15`, `volume_threshold=1.3`.
  - `order_block_institutional.py`: `volume_sigma_threshold=2.5`, `ofi_absorption_threshold=3.0`.

- **NO hay proceso de calibraci√≥n**:
  - ¬øC√≥mo se derivaron estos valores?
  - ¬øSe optimizaron en backtest?
  - ¬øSe recalibran peri√≥dicamente?

**Evidencia**:
- Thresholds en c√≥digo Python, NO en `config/strategy_params.yaml`.
- NO existe `docs/CALIBRATION_METHODOLOGY.md`.

**Impacto**:
- **Medio**:
  - **Thresholds sub√≥ptimos** ‚Üí peor performance.
  - **No adaptaci√≥n a cambios de r√©gimen** ‚Üí estrategias se degradan con el tiempo.
  - **Dif√≠cil ajustar par√°metros** sin tocar c√≥digo.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-009: Falta de matriz de compatibilidad estrategia-s√≠mbolo**

**Descripci√≥n**:
- Estrategias NO declaran en qu√© s√≠mbolos funcionan mejor:
  - ¬ø`kalman_pairs_trading` aplica a FX, commodities, crypto, o todos?
  - ¬ø`nfp_news_event_handler` solo aplica a USD pairs?
  - ¬ø`crisis_mode_volatility_spike` solo aplica a XAUUSD?

- Riesgo: Activar estrategia en s√≠mbolo incompatible ‚Üí p√©rdidas.

**Evidencia**:
- Archivos de estrategias NO tienen:
```python
SUPPORTED_SYMBOLS = ['EURUSD', 'GBPUSD']  # Solo FX majors
```

**Impacto**:
- **Medio**:
  - **Estrategia aplicada a s√≠mbolo incorrecto** ‚Üí performance degradada.
  - **No se puede filtrar autom√°ticamente** qu√© estrategias aplican a qu√© s√≠mbolos.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-010: Estrategias "news" y "calendar" sin integraci√≥n con news feed real**

**Descripci√≥n**:
- Estrategias identificadas:
  - `nfp_news_event_handler.py`: Maneja eventos NFP (Non-Farm Payrolls).
  - `calendar_arbitrage_flows.py`: Arbitraje basado en calendario econ√≥mico.

- **NO hay evidencia de integraci√≥n con news feed**:
  - ¬øDe d√≥nde vienen los datos de news?
  - ¬øHay API de calendario econ√≥mico (Bloomberg, Reuters, FXStreet)?
  - ¬øLatencia del feed?

**Evidencia**:
- NO existe `src/data_feeds/news_feed.py`.
- NO hay configuraci√≥n de API en `config/`.

**Impacto**:
- **Medio**:
  - **Estrategias news-based NO pueden operar** sin feed de noticias.
  - **Latencia de news feed cr√≠tica**: si llega tarde, estrategia no sirve.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

#### **P2 (MENOR) ‚Äì Calidad de c√≥digo, organizaci√≥n**

**P2-004: Naming inconsistente en archivos de estrategias**

**Descripci√≥n**:
- Mix de estilos:
  - `momentum_quality.py` (snake_case, correcto).
  - `nfp_news_event_handler.py` (muy largo).
  - `idp_inducement_distribution.py` (acr√≥nimo IDP sin expansi√≥n).

**Impacto**: **Bajo** - Dificulta navegaci√≥n, NO causa fallos.

**Severidad**: **P2 ‚Äì MENOR**

---

**P2-005: Comentarios agresivos y poco profesionales en c√≥digo**

**Descripci√≥n**:
```python
# order_block_institutional.py:4
üèÜ REAL INSTITUTIONAL IMPLEMENTATION - NO RETAIL DISPLACEMENT GARBAGE
```

- Aunque expresan frustraci√≥n leg√≠tima con retail logic, **tono poco profesional** para c√≥digo institucional.

**Impacto**: **Bajo** - Auditor√≠a interna podr√≠a cuestionar profesionalismo.

**Severidad**: **P2 ‚Äì MENOR**

---

**P2-006: Falta de docstrings completos en m√©todos de estrategias**

**Descripci√≥n**:
- Muchas funciones internas sin docstrings:
```python
def _analyze_momentum_quality(self, market_data, features):
    # Sin docstring completo
```

**Impacto**: **Bajo** - Dificulta mantenimiento.

**Severidad**: **P2 ‚Äì MENOR**

---

### RESUMEN DE RIESGOS MANDATO 2

| Severidad | Cantidad | Cr√≠ticos destacados |
|-----------|----------|---------------------|
| **P0 (CR√çTICO)** | 4 | Sin cat√°logo, Factor crowding masivo, Clasificaci√≥n sin criterios, Conceptos SMC sin validaci√≥n |
| **P1 (IMPORTANTE)** | 5 | Sin integraci√≥n M4/M5 expl√≠cita, Sin backtests, Thresholds hardcoded, Sin matriz s√≠mbolo-estrategia, News sin feed |
| **P2 (MENOR)** | 3 | Naming inconsistente, Comentarios poco profesionales, Docstrings incompletos |
| **TOTAL** | **12** | **4 P0 requieren acci√≥n inmediata** |

---

### MEJORAS INSTITUCIONALES RECOMENDADAS

#### **Acci√≥n M2-001: Crear cat√°logo institucional de estrategias**

**Qu√© hacer**:
1. Crear documento `docs/STRATEGY_CATALOG.md` con tabla completa:

```markdown
# STRATEGY CATALOG ‚Äì SUBLIMINE TradingSystem

| ID | Nombre | Tipo | S√≠mbolos | Holding | Sharpe Target | Status | Owner |
|----|--------|------|----------|---------|---------------|--------|-------|
| S001 | momentum_quality | Momentum | EURUSD,GBPUSD,XAUUSD | 2-6h | >1.5 | PRODUCTION | Core |
| S002 | liquidity_sweep | Liquidity | ALL | <1h | >1.8 | PRODUCTION | Core |
| S003 | order_block_institutional | Microstructure | FX,Metals | 1-4h | >1.6 | PILOT | Advanced |
| S004 | breakout_volume_confirmation | Momentum | ALL | 1-3h | >1.4 | PRODUCTION | Core |
| S005 | mean_reversion_statistical | Mean Reversion | FX | 30min-2h | >1.3 | DEGRADED | Core |
| ... | ... | ... | ... | ... | ... | ... | ... |
| S024 | calendar_arbitrage_flows | News/Event | USD pairs | Minutes | >2.0 | EXPERIMENTAL | Advanced |
```

2. Campos obligatorios:
   - **ID**: Identificador √∫nico (S001-S024).
   - **Nombre**: Nombre de archivo (sin `.py`).
   - **Tipo**: Momentum, Mean Reversion, Liquidity, Microstructure, News, Arbitrage, Volatility.
   - **S√≠mbolos**: Whitelist de s√≠mbolos aplicables.
   - **Holding**: Duraci√≥n t√≠pica de trade.
   - **Sharpe Target**: Sharpe ratio objetivo (backtest).
   - **Status**: EXPERIMENTAL, PILOT, PRODUCTION, DEGRADED, RETIRED.
   - **Owner**: Qui√©n mantiene la estrategia (Core, Advanced, Research).

3. Proceso de actualizaci√≥n:
   - Revisi√≥n mensual de status.
   - Estrategias DEGRADED ‚Üí an√°lisis de causas.
   - Estrategias EXPERIMENTAL ‚Üí backtest antes de PILOT.

**Impacto**: **Muy alto** ‚Äì Visibilidad completa de portfolio de estrategias.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M2-002: An√°lisis de factor crowding y matriz de correlaci√≥n**

**Qu√© hacer**:
1. Crear script `tools/strategy_correlation_analysis.py`:
```python
import pandas as pd
import numpy as np

# Simular se√±ales de todas las estrategias en hist√≥ricos
signals = {
    'momentum_quality': [...],
    'order_flow_toxicity': [...],
    # ...
}

# Calcular matriz de correlaci√≥n
df = pd.DataFrame(signals)
corr_matrix = df.corr()

# Identificar clusters de alta correlaci√≥n (>0.70)
high_corr_pairs = []
for i in range(len(corr_matrix)):
    for j in range(i+1, len(corr_matrix)):
        if corr_matrix.iloc[i,j] > 0.70:
            high_corr_pairs.append((corr_matrix.index[i], corr_matrix.columns[j], corr_matrix.iloc[i,j]))

print("Pares con correlaci√≥n > 0.70:")
for pair in high_corr_pairs:
    print(f"{pair[0]} <-> {pair[1]}: {pair[2]:.2f}")
```

2. Generar `docs/STRATEGY_CORRELATION_MATRIX.md`:
   - Matriz visual de correlaci√≥n.
   - Clusters identificados (ej: "Order Flow Cluster" con 3 estrategias correlaci√≥n >0.80).
   - Recomendaciones:
     - Si 3+ estrategias tienen correlaci√≥n >0.80 ‚Üí considerar como 1 sola para l√≠mites de exposici√≥n.

3. Implementar en ExposureManager:
```python
# Ajustar exposici√≥n por cluster
if strategies_in_cluster(['order_flow_toxicity', 'ofi_refinement', 'footprint_orderflow_clusters']):
    max_cluster_risk = 3.0%  # NO 6% (3 √ó 2%)
```

**Impacto**: **Muy alto** ‚Äì Previene sobre-exposici√≥n a factores correlacionados.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M2-003: Definir criterios de lifecycle de estrategias**

**Qu√© hacer**:
1. Crear `docs/STRATEGY_LIFECYCLE_POLICY.md`:

```markdown
# STRATEGY LIFECYCLE POLICY

## Estados

### EXPERIMENTAL
- Criterios de entrada:
  - Idea fundamentada en paper acad√©mico o evidencia emp√≠rica preliminar.
  - C√≥digo implementado con tests b√°sicos.
- Restricciones:
  - NO puede operar en producci√≥n.
  - Solo backtesting en historical data.

### PILOT
- Criterios de promoci√≥n desde EXPERIMENTAL:
  - Backtest con Sharpe > 1.0 en ‚â•12 meses de datos.
  - Win rate > 50%.
  - Max DD < 15%.
  - Validaci√≥n out-of-sample (20% de datos).
- Restricciones:
  - Puede operar en paper trading.
  - L√≠mite de riesgo: 0.5% por idea (vs 2% en PRODUCTION).

### PRODUCTION
- Criterios de promoci√≥n desde PILOT:
  - Paper trading exitoso durante ‚â•3 meses.
  - Sharpe > 1.3.
  - Comportamiento estable (no spikes an√≥malos).
  - Revisi√≥n por Model Risk.
- Restricciones:
  - L√≠mite de riesgo: hasta 2% por idea.

### DEGRADED
- Criterios de degradaci√≥n desde PRODUCTION:
  - Sharpe cae <0.5 durante 2 meses consecutivos.
  - Drawdown > 20% en 1 mes.
  - Win rate cae <40%.
- Acciones:
  - Reducir riesgo a 0.5% por idea.
  - An√°lisis de causas (regime change, strategy decay, data quality).
  - Decisi√≥n: recalibrar o RETIRED.

### RETIRED
- Criterios de retiro desde DEGRADED:
  - No se identifica causa corregible.
  - Sharpe negativo durante 3 meses.
- Acciones:
  - Desactivar completamente.
  - Archivar c√≥digo en `src/strategies/retired/`.
```

2. Implementar en c√≥digo:
```python
# src/governance/strategy_lifecycle.py
class StrategyLifecycleManager:
    def evaluate_promotion(self, strategy_id, metrics):
        if metrics['sharpe'] > 1.0 and metrics['max_dd'] < 0.15:
            return 'PILOT'
        # ...
```

**Impacto**: **Muy alto** ‚Äì Decisiones objetivas sobre estrategias.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M2-004: Validaci√≥n emp√≠rica de conceptos SMC/ICT**

**Qu√© hacer**:
1. Para cada estrategia con conceptos SMC (order blocks, FVG, inducement):
   - Backtest riguroso en ‚â•24 meses de datos.
   - Validaci√≥n out-of-sample en 20% de datos.
   - Comparaci√≥n con baseline (buy-and-hold, random entry).

2. Documentar en `docs/STRATEGY_VALIDATION_REPORTS.md`:
```markdown
## order_block_institutional

### Definici√≥n cuantitativa
- Order block = √∫ltima vela antes de displacement >2œÉ volumen.
- Displacement = movimiento >2√óATR en <3 velas.
- Retest = precio vuelve a zona ¬±0.5√óATR del OB.

### Backtest
- Per√≠odo: 2021-01-01 a 2024-12-31 (4 a√±os).
- Sharpe: 1.62.
- Win rate: 68%.
- Max DD: 12%.

### Out-of-sample
- Per√≠odo: 2023-07-01 a 2024-12-31 (18 meses).
- Sharpe: 1.54 (degradaci√≥n <5%, aceptable).

### Conclusi√≥n
- ‚úÖ APROBADA para PILOT.
- Concepto "order block" validado cuantitativamente.
```

3. Si estrategia NO pasa validaci√≥n:
   - Status = EXPERIMENTAL o RETIRED.
   - NO promoci√≥n a PILOT.

**Impacto**: **Muy alto** ‚Äì Elimina estrategias no probadas, aumenta credibilidad.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M2-005: Declarar dependencies expl√≠citas en estrategias**

**Qu√© hacer**:
1. A√±adir a cada estrategia:
```python
# momentum_quality.py
class MomentumQuality(StrategyBase):
    METADATA = {
        'id': 'S001',
        'name': 'momentum_quality',
        'type': 'Momentum',
        'supported_symbols': ['EURUSD', 'GBPUSD', 'XAUUSD', 'BTCUSD', 'US50'],
        'holding_period': '2-6h',
        'dependencies': {
            'microstructure': ['vpin', 'ofi'],  # Requiere VPIN y OFI
            'multiframe': ['htf_trend'],        # Requiere HTF trend
            'data_health': 0.70,                 # M√≠nimo data health score
        },
        'risk_params': {
            'max_risk_per_trade': 2.0,           # % m√°ximo
            'max_open_trades': 3,
        },
    }
```

2. Validar dependencies en runtime:
```python
def evaluate(self, market_data, features):
    # Validar que microstructure est√° disponible
    if 'vpin' not in features or features['vpin'] is None:
        self.logger.warning("VPIN not available, skipping evaluation")
        return []

    if features['data_health_score'] < self.METADATA['dependencies']['data_health']:
        self.logger.warning(f"Data health too low: {features['data_health_score']}")
        return []
```

**Impacto**: **Medio-Alto** ‚Äì Debugging m√°s f√°cil, integraci√≥n m√°s robusta.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M2-006: Generar backtests documentados para todas las estrategias**

**Qu√© hacer**:
1. Crear framework de backtesting estandarizado:
```python
# tools/backtest_runner.py
def run_backtest(strategy_class, data, config):
    results = {
        'sharpe': ...,
        'max_dd': ...,
        'win_rate': ...,
        'profit_factor': ...,
        'trades': [...],
    }
    return results
```

2. Ejecutar backtests para todas las estrategias:
```bash
python tools/backtest_runner.py --strategy momentum_quality --start 2021-01-01 --end 2024-12-31
```

3. Archivar resultados en `backtests/YYYY-MM-DD/`:
```
backtests/
  2025-11-13/
    momentum_quality_backtest.json
    liquidity_sweep_backtest.json
    ...
```

4. Generar reporte consolidado en `docs/BACKTEST_RESULTS.md`:
```markdown
| Estrategia | Sharpe | Win Rate | Max DD | Status |
|------------|--------|----------|--------|--------|
| momentum_quality | 1.52 | 64% | 11% | ‚úÖ PASS |
| liquidity_sweep | 1.78 | 71% | 9% | ‚úÖ PASS |
| idp_inducement_distribution | 0.42 | 48% | 22% | ‚ùå FAIL |
```

**Impacto**: **Medio-Alto** ‚Äì Evidencia emp√≠rica de performance.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M2-007: Externalizar thresholds a config centralizado**

**Qu√© hacer**:
1. Crear `config/strategy_params.yaml`:
```yaml
momentum_quality:
  price_threshold: 0.30
  volume_threshold: 1.40
  vpin_clean_max: 0.30
  min_quality_score: 0.65

liquidity_sweep:
  penetration_min: 3
  penetration_max: 15
  volume_threshold: 1.3
```

2. Cargar en estrategias:
```python
import yaml

with open('config/strategy_params.yaml') as f:
    params = yaml.safe_load(f)

config = params['momentum_quality']
strategy = MomentumQuality(config)
```

3. Proceso de recalibraci√≥n:
   - Mensual: revisar performance de estrategias.
   - Si Sharpe cae <1.0 ‚Üí recalibrar thresholds en grid search.
   - Actualizar `config/strategy_params.yaml`.

**Impacto**: **Medio** ‚Äì Facilita ajustes sin tocar c√≥digo.

**Prioridad**: **P1 ‚Äì MEDIA**

---

#### **Acci√≥n M2-008: Crear matriz estrategia-s√≠mbolo**

**Qu√© hacer**:
1. En `METADATA` de cada estrategia, declarar:
```python
'supported_symbols': ['EURUSD', 'GBPUSD', 'XAUUSD'],
```

2. Implementar filtro en arbiter:
```python
def filter_signals_by_symbol_compatibility(signals):
    filtered = []
    for signal in signals:
        strategy = get_strategy(signal.strategy_id)
        if signal.symbol in strategy.METADATA['supported_symbols']:
            filtered.append(signal)
        else:
            logger.warning(f"Signal from {signal.strategy_id} rejected: {signal.symbol} not supported")
    return filtered
```

**Impacto**: **Medio** ‚Äì Previene aplicaci√≥n de estrategias a s√≠mbolos incompatibles.

**Prioridad**: **P1 ‚Äì MEDIA**

---

#### **Acci√≥n M2-009: Integrar news feed para estrategias event-driven**

**Qu√© hacer**:
1. Integrar news feed API (ej: FXStreet, Investing.com):
```python
# src/data_feeds/news_feed.py
class NewsFeed:
    def get_upcoming_events(self, currency, hours_ahead=24):
        # Retorna eventos NFP, PMI, CPI, etc.
        return [
            {'timestamp': ..., 'event': 'NFP', 'currency': 'USD', 'impact': 'HIGH'},
        ]
```

2. Conectar a estrategias:
```python
# nfp_news_event_handler.py
def evaluate(self, market_data, features):
    upcoming_events = self.news_feed.get_upcoming_events('USD', hours_ahead=2)

    for event in upcoming_events:
        if event['event'] == 'NFP' and event['impact'] == 'HIGH':
            # Preparar estrategia pre-NFP
```

**Impacto**: **Medio** ‚Äì Activa estrategias news-based.

**Prioridad**: **P1 ‚Äì MEDIA**

---

#### **Acci√≥n M2-010: Refactoring de naming y limpieza de c√≥digo**

**Qu√© hacer**:
1. Renombrar archivos largos:
   - `nfp_news_event_handler.py` ‚Üí `news_nfp_handler.py`.
   - `idp_inducement_distribution.py` ‚Üí `smc_idp_pattern.py` (y documentar que IDP = Inducement-Distribution-Price).

2. Eliminar comentarios agresivos:
```python
# ANTES
"""üèÜ REAL INSTITUTIONAL - NO RETAIL GARBAGE"""

# DESPU√âS
"""
Institutional order block strategy using order flow microstructure.
Based on: Hasbrouck (2007), Easley et al. (2012).
"""
```

3. A√±adir docstrings completos:
```python
def _analyze_momentum_quality(self, market_data: pd.DataFrame, features: Dict) -> Optional[Dict]:
    """
    Analiza calidad de momentum usando confluencia de factores.

    Args:
        market_data: DataFrame con OHLCV de √∫ltimos N per√≠odos
        features: Dict con features pre-calculados (VPIN, OFI, etc.)

    Returns:
        Dict con quality_score, direction, strength, o None si no califica
    """
```

**Impacto**: **Bajo** ‚Äì Mejora profesionalismo del c√≥digo.

**Prioridad**: **P2 ‚Äì BAJA**

---

### PLAN DE ACCI√ìN PRIORIZADO ‚Äì MANDATO 2

**Fase inmediata (Semana 1)**:
1. **M2-001**: Crear `STRATEGY_CATALOG.md` con todas las estrategias.
2. **M2-002**: An√°lisis de correlaci√≥n entre estrategias.
3. **M2-003**: Definir `STRATEGY_LIFECYCLE_POLICY.md`.
4. **M2-004**: Validaci√≥n emp√≠rica de estrategias SMC (al menos 3 principales).

**Fase corto plazo (Semana 2-3)**:
5. **M2-005**: Declarar dependencies en METADATA de estrategias.
6. **M2-006**: Backtests documentados para top 10 estrategias.
7. **M2-007**: Externalizar thresholds a `config/strategy_params.yaml`.

**Fase medio plazo (Mes 1)**:
8. **M2-008**: Matriz estrategia-s√≠mbolo.
9. **M2-009**: Integraci√≥n news feed para estrategias event-driven.
10. **M2-010**: Refactoring de naming y limpieza de comentarios.

---

### VEREDICTO FINAL ‚Äì MANDATO 2

**Estado**: ‚ö†Ô∏è **ZOO DE ESTRATEGIAS SIN GOBERNANZA ‚Äì NO APTO PARA PRODUCCI√ìN**

**Logros**:
- ‚úÖ 24 estrategias implementadas.
- ‚úÖ C√≥digo mayormente funcional.
- ‚úÖ Intento de formalizaci√≥n cuantitativa.

**Fallas institucionales**:
- ‚ùå **Sin cat√°logo formal** ‚Üí imposible saber qu√© est√° activo.
- ‚ùå **Factor crowding masivo** ‚Üí sobre-exposici√≥n oculta.
- ‚ùå **Clasificaci√≥n "broken/hybrid/approved" sin criterios** ‚Üí decisiones subjetivas.
- ‚ùå **Conceptos SMC sin validaci√≥n emp√≠rica rigurosa** ‚Üí riesgo de overfitting.
- ‚ùå **Sin backtests documentados** ‚Üí no hay evidencia de que funcionen.

**Recomendaci√≥n**:
**NO DESPLEGAR M√ÅS DE 5 ESTRATEGIAS A PRODUCCI√ìN** hasta completar:
- M2-001 (Cat√°logo).
- M2-002 (An√°lisis de correlaci√≥n).
- M2-003 (Lifecycle policy).
- M2-004 (Validaci√≥n emp√≠rica de SMC).
- M2-006 (Backtests documentados).

**Estrategias recomendadas para PILOT inicial** (tras validaci√≥n):
1. `momentum_quality` (si backtest >1.3 Sharpe).
2. `liquidity_sweep` (si backtest >1.5 Sharpe).
3. `breakout_volume_confirmation` (cl√°sica, probablemente robusta).
4. `mean_reversion_statistical` (si no est√° degradada).
5. `order_flow_toxicity` (representante de cluster order flow).

**Resto de estrategias**: EXPERIMENTAL hasta validaci√≥n.

---

**FIN AUDITOR√çA MANDATO 2**

---

## MANDATO 3 ‚Äì AUDITOR√çA INSTITUCIONAL

**Alcance**: Brain-layer (SignalArbitrator, ML Adaptive Engine), meta-capa de decisi√≥n, integraci√≥n con QualityScorer/MicrostructureEngine/ExposureManager.

**Estado actual**: DISE√ëADO PERO SIN GOVERNANCE ‚Äì **Caja negra potencialmente peligrosa sin l√≠mites claros ni model risk management**.

---

### RIESGOS / DEBILIDADES DETECTADAS

#### **P0 (CR√çTICO) ‚Äì Riesgos que pueden causar p√©rdidas severas o anular controles de riesgo**

**P0-009: Brain-layer puede modificar decisiones sin l√≠mites documentados**

**Descripci√≥n**:
- `brain.py` y `ml_adaptive_engine.py` implementan:
  - `SignalArbitrator`: Selecciona entre se√±ales conflictivas.
  - `ML Adaptive Engine`: Aprende de trades pasados y ajusta par√°metros.
- **NO existe documento que defina** qu√© puede y NO puede tocar el brain-layer:
  - ¬øPuede modificar risk caps (2% por idea)?
  - ¬øPuede anular SL estructurales?
  - ¬øPuede cambiar pesos del QualityScorer?
  - ¬øPuede desactivar estrategias?
  - ¬øPuede ignorar reglas de ExposureManager?

**Evidencia**:
- `brain.py:56-148`: `_score_signal()` usa pesos hardcodeados (40%, 25%, 20%, 10%, 5%).
- `ml_adaptive_engine.py`: Implementa "Parameter Optimizer" y "Risk Parameter Adapter".
- **NO existe `docs/BRAIN_LAYER_GOVERNANCE.md`** con √°reas prohibidas.
- **NO existe `docs/MODEL_RISK_POLICY.md`** que defina c√≥mo se valida el brain-layer.

**Impacto**:
- **Muy alto**:
  - **Brain-layer descontrolado puede anular risk caps** ‚Üí p√©rdidas catastr√≥ficas.
  - **Puede degradar QualityScorer** ajustando pesos incorrectamente.
  - **Sin l√≠mites, puede entrar en loop de auto-destrucci√≥n** (ej: ajustar par√°metros tras p√©rdidas, causando m√°s p√©rdidas).
  - **Auditor√≠a rechazar√≠a sistema** sin governance de modelo predictivo.

**Escenario de fallo**:
```
1. Brain-layer detecta que estrategia X pierde dinero.
2. Ajusta pesos del QualityScorer para bajar peso de 'pedigree'.
3. Ahora todas las estrategias pasan threshold, incluyendo malas.
4. Sistema genera m√°s p√©rdidas.
5. Brain-layer sobre-reacciona, desactiva estrategias buenas.
‚Üí Colapso del sistema.
```

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-010: ML Adaptive Engine sin challenger model ni validaci√≥n independiente**

**Descripci√≥n**:
- `ml_adaptive_engine.py` implementa:
  - `RandomForestClassifier` para predecir √©xito de se√±ales.
  - `GradientBoostingRegressor` para predecir PnL.
  - `Ridge` regression para optimizar par√°metros.
- **Problemas**:
  - NO hay **challenger model** (segundo modelo que valida predicciones del primero).
  - NO hay **backtesting del brain-layer** (¬øfunciona realmente o genera noise?).
  - NO hay **m√©tricas de calidad del modelo** (accuracy, precision, recall, AUC).
  - NO hay **validaci√≥n out-of-sample** antes de aplicar ajustes.

**Evidencia**:
- `ml_adaptive_engine.py:38-40`: Imports de sklearn (RandomForest, GradientBoosting, Ridge).
- NO existe `docs/ML_MODEL_VALIDATION.md`.
- NO hay carpeta `models/validation/` con m√©tricas.

**Impacto**:
- **Muy alto**:
  - **Modelo puede overfittear** a ruido ‚Üí decisiones incorrectas.
  - **Sin validaci√≥n, modelo puede degradarse** sin que nadie lo detecte.
  - **Riesgo de data leakage** (entrenar con datos futuros por error).
  - **Model Risk rechazar√≠a modelo** sin validaci√≥n rigurosa.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-011: Ausencia de rollback mechanism si brain-layer se comporta mal**

**Descripci√≥n**:
- Brain-layer ajusta par√°metros din√°micamente.
- **NO hay mecanismo de rollback** si:
  - Ajustes causan p√©rdidas > X%.
  - Modelo ML se degrada (accuracy cae).
  - Brain-layer rechaza se√±ales buenas consistentemente.

**Evidencia**:
- NO existe `docs/BRAIN_LAYER_ROLLBACK_POLICY.md`.
- NO hay c√≥digo que detecte comportamiento an√≥malo del brain-layer.
- NO hay snapshot de par√°metros antes de ajustes.

**Impacto**:
- **Alto**:
  - **Ajustes malos son irreversibles** ‚Üí sistema queda degradado.
  - **No se puede volver a √∫ltima configuraci√≥n buena** r√°pidamente.
  - **P√©rdidas se acumulan** mientras se diagnostica problema.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-012: Data leakage potencial en learning loop**

**Descripci√≥n**:
- `TradeMemoryDatabase` almacena trades completos.
- **Riesgo**: Si learning loop usa datos del futuro para calibrar decisiones presentes:
  - Ej: Ajustar pesos del QualityScorer usando PnL de trades que a√∫n no cerraron.
  - Ej: Entrenar modelo ML con datos de r√©gimen futuro.

**Evidencia**:
- `ml_adaptive_engine.py`: Implementa `TradeMemoryDatabase` y `SignalRecord`.
- NO hay validaci√≥n expl√≠cita de time-series split (train/validation temporal).
- NO existe `docs/DATA_GOVERNANCE_ML.md` que prevenga data leakage.

**Impacto**:
- **Muy alto**:
  - **Backtest falso positivo**: Modelo parece funcionar en backtest pero falla en vivo.
  - **Overfitting severo** a datos hist√≥ricos.
  - **P√©rdidas en producci√≥n** por decisiones basadas en datos contaminados.

**Severidad**: **P0 ‚Äì CR√çTICO**

---

#### **P1 (IMPORTANTE) ‚Äì Degrada calidad institucional**

**P1-011: Pesos del SignalArbitrator hardcodeados sin justificaci√≥n emp√≠rica**

**Descripci√≥n**:
- `brain.py:108-141`: Scoring de se√±ales usa pesos:
  - Quality: 40%
  - Performance: 25%
  - Regime: 20%
  - Risk-Reward: 10%
  - Timing: 5%

- **NO hay justificaci√≥n**:
  - ¬øPor qu√© 40% quality y no 50%?
  - ¬øPor qu√© timing solo 5% cuando microestructura es cr√≠tica?
  - ¬øSe derivaron de backtest o son arbitrarios?

**Evidencia**:
- Pesos hardcodeados en c√≥digo.
- NO existe `docs/ARBITRATOR_WEIGHT_CALIBRATION.md`.

**Impacto**:
- **Medio**:
  - **Pesos sub√≥ptimos** ‚Üí selecci√≥n de se√±ales no maximiza Sharpe.
  - **Sin calibraci√≥n, pesos se vuelven obsoletos** con cambios de mercado.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-012: Regime-strategy fit matrix hardcodeada sin actualizaci√≥n din√°mica**

**Descripci√≥n**:
- `brain.py:183-223`: `fit_matrix` hardcodeado con valores tipo:
```python
'TREND_STRONG_UP': {
    'momentum_quality': 1.0,
    'breakout_volume_confirmation': 0.95,
    # ...
}
```

- **Problemas**:
  - Valores fijos sin proceso de calibraci√≥n.
  - NO se actualiza con performance real de estrategias en cada r√©gimen.
  - Si r√©gimen cambia, matriz puede quedar obsoleta.

**Evidencia**:
- `brain.py:183`: `fit_matrix` dict hardcodeado.
- NO existe `tools/calibrate_regime_fit.py`.

**Impacto**:
- **Medio**:
  - **Estrategias mal asignadas a reg√≠menes** ‚Üí peor performance.
  - **No adaptaci√≥n a cambios estructurales de mercado**.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-013: ML Adaptive Engine sin m√©tricas de monitoreo continuo**

**Descripci√≥n**:
- Modelos ML entrenados, pero:
  - **NO hay m√©tricas de health**:
    - Accuracy en ventana deslizante.
    - Precision/Recall en √∫ltimas N predicciones.
    - AUC degrad√°ndose.
  - **NO hay alertas** si modelo se degrada.

**Evidencia**:
- NO existe `src/monitoring/ml_model_monitor.py`.
- NO hay dashboard de m√©tricas ML.

**Impacto**:
- **Medio**:
  - **Modelo degrada silenciosamente** ‚Üí decisiones incorrectas sin detecci√≥n.
  - **No se sabe cu√°ndo re-entrenar** modelo.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-014: Falta de separaci√≥n research vs production en ML pipeline**

**Descripci√≥n**:
- C√≥digo ML mezclado con l√≥gica de producci√≥n.
- **NO hay separaci√≥n clara**:
  - ¬øD√≥nde se entrenan modelos? (research environment).
  - ¬øD√≥nde se validan? (validation environment).
  - ¬øD√≥nde se despliegan? (production).
  - ¬øC√≥mo se versionan modelos?

**Evidencia**:
- NO existe `models/` con versionado (v1.0, v1.1, etc.).
- NO hay `MLflow` o sistema de tracking de experimentos.

**Impacto**:
- **Medio**:
  - **Modelos experimentales pueden llegar a producci√≥n** sin validaci√≥n.
  - **Dificulta rollback** a versi√≥n anterior de modelo.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-015: Brain-layer sin circuit breaker ante comportamiento an√≥malo**

**Descripci√≥n**:
- Brain-layer puede generar decisiones an√≥malas:
  - Rechazar 100% de se√±ales durante 1 hora.
  - Aprobar se√±ales de muy baja calidad (<0.30).
  - Cambiar pesos del arbitrator abruptamente.

- **NO hay circuit breaker** que detecte y detenga comportamiento an√≥malo.

**Evidencia**:
- NO existe `src/safety/brain_circuit_breaker.py`.
- NO hay reglas tipo:
```python
if rejection_rate_last_hour > 0.95:
    # ALERT: Brain-layer rechazando TODO
    switch_to_manual_mode()
```

**Impacto**:
- **Medio**:
  - **Comportamiento an√≥malo no detectado** ‚Üí p√©rdida de oportunidades o p√©rdidas materiales.

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

#### **P2 (MENOR) ‚Äì Calidad de c√≥digo, documentaci√≥n**

**P2-007: Comentarios "NOT retail" agresivos en brain.py**

**Descripci√≥n**:
```python
# brain.py:3
This is NOT a simple signal combiner. This is an advanced orchestration layer
that thinks at the PORTFOLIO level, not individual trade level.
```

- Tono defensivo poco profesional.

**Impacto**: **Bajo** - Auditor√≠a podr√≠a cuestionar profesionalismo.

**Severidad**: **P2 ‚Äì MENOR**

---

**P2-008: Falta de docstrings completos en m√©todos ML**

**Descripci√≥n**:
- Muchas funciones en `ml_adaptive_engine.py` sin docstrings completos:
  - Par√°metros de entrada.
  - Outputs esperados.
  - Excepciones.

**Impacto**: **Bajo** - Dificulta mantenimiento.

**Severidad**: **P2 ‚Äì MENOR**

---

### RESUMEN DE RIESGOS MANDATO 3

| Severidad | Cantidad | Cr√≠ticos destacados |
|-----------|----------|---------------------|
| **P0 (CR√çTICO)** | 4 | Sin l√≠mites claros, Sin challenger model, Sin rollback, Data leakage potencial |
| **P1 (IMPORTANTE)** | 5 | Pesos hardcoded, Fit matrix fija, Sin monitoreo ML, Sin research/production split, Sin circuit breaker |
| **P2 (MENOR)** | 2 | Comentarios agresivos, Docstrings incompletos |
| **TOTAL** | **11** | **4 P0 requieren acci√≥n inmediata** |

---

### MEJORAS INSTITUCIONALES RECOMENDADAS

#### **Acci√≥n M3-001: Definir governance estricta del brain-layer**

**Qu√© hacer**:
1. Crear `docs/BRAIN_LAYER_GOVERNANCE.md`:

```markdown
# BRAIN LAYER GOVERNANCE

## √Åreas Prohibidas (NO TOCAR JAM√ÅS)

### 1. Risk Caps
- Brain-layer **NUNCA puede modificar**:
  - M√°ximo 2.0% riesgo por idea.
  - Caps de exposici√≥n total (s√≠mbolo, estrategia, direcci√≥n).
  - Stop loss estructurales.

### 2. Quality Score Threshold
- Brain-layer **NO puede bajar** threshold de QualityScorer <0.50.
- Puede sugerir ajustes de pesos SOLO dentro de bandas:
  - Pedigree: [0.20, 0.30]
  - Signal: [0.20, 0.30]
  - Microstructure: [0.15, 0.25]
  - Data Health: [0.10, 0.20]
  - Portfolio: [0.10, 0.20]

### 3. Estrategias
- Brain-layer puede:
  - ‚úÖ Ajustar pesos de estrategias en fit_matrix dentro de ¬±0.10.
  - ‚úÖ Marcar estrategias como "under review".
- Brain-layer NO puede:
  - ‚ùå Desactivar estrategias PRODUCTION sin aprobaci√≥n humana.
  - ‚ùå Activar estrategias EXPERIMENTAL en producci√≥n.

### 4. ExposureManager
- Brain-layer NO puede:
  - ‚ùå Anular l√≠mites de correlaci√≥n.
  - ‚ùå Ignorar exposici√≥n por factor macro.

## √Åreas Permitidas (CON RESTRICCIONES)

### 1. Signal Arbitration
- ‚úÖ Seleccionar entre se√±ales conflictivas.
- ‚úÖ Ajustar pesos de arbitrator dentro de bandas predefinidas.

### 2. Regime Fit
- ‚úÖ Ajustar fit_matrix dentro de ¬±0.10 de valor base.
- ‚úÖ Sugerir recalibraci√≥n de reg√≠menes.

### 3. Parameter Tuning
- ‚úÖ Ajustar thresholds de estrategias dentro de ¬±20% del valor base.
- ‚úÖ Solo si backtest valida mejora.

## Proceso de Aprobaci√≥n de Cambios

1. Brain-layer propone cambio ‚Üí log detallado.
2. Cambio se valida en **paper trading** durante ‚â•1 semana.
3. Si Sharpe mejora ‚â•10% ‚Üí aprobaci√≥n autom√°tica.
4. Si cambio afecta risk caps ‚Üí aprobaci√≥n humana obligatoria.
```

2. Implementar en c√≥digo:
```python
# src/governance/brain_governor.py
class BrainGovernor:
    FORBIDDEN_ACTIONS = [
        'modify_risk_caps',
        'disable_production_strategy',
        'bypass_exposure_limits',
    ]

    ALLOWED_PARAMETER_RANGES = {
        'quality_score_weights': {
            'pedigree': (0.20, 0.30),
            'signal': (0.20, 0.30),
            # ...
        },
        'fit_matrix_adjustment': (-0.10, +0.10),
    }

    def validate_action(self, action, params):
        if action in self.FORBIDDEN_ACTIONS:
            raise ForbiddenActionError(f"{action} is forbidden")

        if action == 'adjust_quality_weights':
            for key, value in params.items():
                min_val, max_val = self.ALLOWED_PARAMETER_RANGES['quality_score_weights'][key]
                if not (min_val <= value <= max_val):
                    raise ValueError(f"{key}={value} out of range [{min_val}, {max_val}]")

        return True
```

**Impacto**: **Muy alto** ‚Äì Previene que brain-layer cause da√±os.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M3-002: Implementar challenger model y validaci√≥n rigurosa**

**Qu√© hacer**:
1. Crear `docs/ML_MODEL_VALIDATION.md`:

```markdown
# ML MODEL VALIDATION POLICY

## Requerimientos M√≠nimos

Cualquier modelo ML debe cumplir:
1. **Backtest out-of-sample** ‚â•6 meses.
2. **Accuracy ‚â•65%** en predecir se√±ales ganadoras.
3. **Precision ‚â•60%** (evitar falsos positivos).
4. **Walk-forward validation** en ‚â•3 per√≠odos.

## Challenger Model

Todo modelo en producci√≥n debe tener challenger:
- Modelo A (producci√≥n) vs Modelo B (challenger).
- Comparaci√≥n mensual de performance.
- Si challenger supera modelo A durante 2 meses ‚Üí promoci√≥n.

## M√©tricas de Monitoreo

En ventana deslizante de 30 d√≠as:
- Accuracy actual vs esperada.
- Drift detection (distribuci√≥n de features cambia).
- Calibration error (predicciones vs realidad).

Si alguna m√©trica degrada >20% ‚Üí ALERT + rollback a modelo anterior.
```

2. Implementar challenger model:
```python
# src/ml/challenger_model.py
class ChallengerModelSystem:
    def __init__(self):
        self.production_model = load_model('models/production/v1.2.pkl')
        self.challenger_model = load_model('models/challenger/v1.3.pkl')

        self.production_metrics = deque(maxlen=100)
        self.challenger_metrics = deque(maxlen=100)

    def predict(self, features):
        # Ambos modelos predicen
        prod_pred = self.production_model.predict(features)
        chall_pred = self.challenger_model.predict(features)

        # Usar producci√≥n para decisi√≥n
        # Registrar ambos para comparaci√≥n
        self.production_metrics.append({'prediction': prod_pred, ...})
        self.challenger_metrics.append({'prediction': chall_pred, ...})

        return prod_pred

    def evaluate_challenger(self):
        """Comparar performance mensual."""
        prod_accuracy = calculate_accuracy(self.production_metrics)
        chall_accuracy = calculate_accuracy(self.challenger_metrics)

        if chall_accuracy > prod_accuracy + 0.05:  # +5% mejor
            logger.warning("Challenger model outperforms production")
            # Trigger human review
```

**Impacto**: **Muy alto** ‚Äì Valida que modelo ML realmente funciona.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M3-003: Implementar rollback mechanism autom√°tico**

**Qu√© hacer**:
1. Snapshot de par√°metros antes de cada ajuste:
```python
# src/safety/parameter_snapshot.py
class ParameterSnapshotManager:
    def __init__(self):
        self.snapshots = deque(maxlen=100)

    def take_snapshot(self, component_name):
        """Guarda estado actual de par√°metros."""
        snapshot = {
            'timestamp': datetime.now(),
            'component': component_name,
            'parameters': get_current_parameters(component_name),
            'performance_before': get_recent_sharpe(),
        }
        self.snapshots.append(snapshot)
        logger.info(f"Snapshot taken: {component_name}")

    def rollback_to_snapshot(self, snapshot_id):
        """Revierte a snapshot anterior."""
        snapshot = self.snapshots[snapshot_id]
        apply_parameters(snapshot['component'], snapshot['parameters'])
        logger.warning(f"Rolled back to snapshot {snapshot_id}")
```

2. Detector de degradaci√≥n:
```python
# src/safety/degradation_detector.py
def detect_brain_degradation():
    """Detecta si ajustes del brain-layer causaron degradaci√≥n."""
    # M√©tricas √∫ltimas 24h vs 7 d√≠as previos
    recent_sharpe = calculate_sharpe(hours=24)
    baseline_sharpe = calculate_sharpe(days=7)

    if recent_sharpe < baseline_sharpe * 0.70:  # -30% degradaci√≥n
        logger.critical("DEGRADATION DETECTED: Sharpe dropped 30%")
        # Rollback autom√°tico
        snapshot_manager.rollback_to_last_good_snapshot()
        send_alert("Brain-layer rolled back due to degradation")
```

**Impacto**: **Alto** ‚Äì Recuperaci√≥n r√°pida ante problemas.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M3-004: Prevenir data leakage con time-series split estricto**

**Qu√© hacer**:
1. Crear `docs/DATA_GOVERNANCE_ML.md`:

```markdown
# DATA GOVERNANCE FOR ML

## Reglas Estrictas

### 1. Time-Series Split
- Training data: hasta timestamp T.
- Validation data: (T, T+30 d√≠as].
- Test data: (T+30, T+60 d√≠as].
- **NUNCA** usar datos futuros para entrenar.

### 2. Feature Engineering
- Solo usar features disponibles en el momento de decisi√≥n.
- Prohibido:
  - ‚ùå Usar PnL de trade antes de cerrar.
  - ‚ùå Usar r√©gimen futuro.
  - ‚ùå Lookahead bias en indicadores.

### 3. Validaci√≥n
- Walk-forward testing obligatorio.
- Re-entrenar modelo cada 30 d√≠as con datos nuevos.
```

2. Implementar en c√≥digo:
```python
# tools/ml_training.py
def train_model_with_strict_split(data, target_variable):
    """Entrena modelo con split temporal estricto."""
    # Ordenar por timestamp
    data = data.sort_values('timestamp')

    # Split: 70% train, 15% validation, 15% test
    n = len(data)
    train_end = int(n * 0.70)
    val_end = int(n * 0.85)

    train_data = data.iloc[:train_end]
    val_data = data.iloc[train_end:val_end]
    test_data = data.iloc[val_end:]

    # Verificar no overlap
    assert train_data['timestamp'].max() < val_data['timestamp'].min()
    assert val_data['timestamp'].max() < test_data['timestamp'].min()

    # Entrenar
    model = RandomForestClassifier()
    model.fit(train_data.drop(columns=['timestamp', target_variable]),
              train_data[target_variable])

    # Validar
    val_accuracy = model.score(val_data.drop(columns=['timestamp', target_variable]),
                                val_data[target_variable])

    logger.info(f"Validation accuracy: {val_accuracy:.3f}")

    return model
```

**Impacto**: **Muy alto** ‚Äì Previene overfitting falso.

**Prioridad**: **P0 ‚Äì INMEDIATA**

---

#### **Acci√≥n M3-005: Calibrar pesos del SignalArbitrator emp√≠ricamente**

**Qu√© hacer**:
1. Grid search para encontrar pesos √≥ptimos:
```python
# tools/calibrate_arbitrator_weights.py
def calibrate_arbitrator_weights(historical_signals, outcomes):
    """
    Encuentra pesos √≥ptimos del arbitrator via grid search.

    Args:
        historical_signals: Se√±ales pasadas con scores de cada componente
        outcomes: PnL real de cada se√±al

    Returns:
        Pesos √≥ptimos que maximizan Sharpe
    """
    best_sharpe = -np.inf
    best_weights = None

    # Grid search
    for w_quality in np.arange(0.30, 0.50, 0.05):
        for w_perf in np.arange(0.15, 0.35, 0.05):
            for w_regime in np.arange(0.10, 0.30, 0.05):
                for w_rr in np.arange(0.05, 0.20, 0.05):
                    w_timing = 1.0 - (w_quality + w_perf + w_regime + w_rr)

                    if w_timing < 0 or w_timing > 0.15:
                        continue

                    weights = {
                        'quality': w_quality,
                        'performance': w_perf,
                        'regime': w_regime,
                        'risk_reward': w_rr,
                        'timing': w_timing,
                    }

                    # Simular selecci√≥n con estos pesos
                    sharpe = simulate_arbitrator_with_weights(historical_signals, outcomes, weights)

                    if sharpe > best_sharpe:
                        best_sharpe = sharpe
                        best_weights = weights

    logger.info(f"Best weights: {best_weights} (Sharpe: {best_sharpe:.3f})")
    return best_weights
```

2. Documentar en `docs/ARBITRATOR_WEIGHT_CALIBRATION.md`:
```markdown
## Calibraci√≥n Hist√≥rica

Per√≠odo: 2023-01-01 a 2024-12-31
Pesos √≥ptimos encontrados:
- Quality: 38%
- Performance: 28%
- Regime: 18%
- Risk-Reward: 11%
- Timing: 5%

Sharpe resultante: 1.82 (vs 1.54 con pesos anteriores).

Pr√≥xima recalibraci√≥n: 2025-04-01.
```

**Impacto**: **Medio-Alto** ‚Äì Pesos derivados emp√≠ricamente.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M3-006: Implementar actualizaci√≥n din√°mica de fit_matrix**

**Qu√© hacer**:
1. Recalibrar fit_matrix cada 30 d√≠as basado en performance real:
```python
# tools/calibrate_regime_fit.py
def recalibrate_regime_fit_matrix(trade_history):
    """
    Recalibra fit_matrix basado en performance real de estrategias por r√©gimen.

    Args:
        trade_history: Historial de trades con r√©gimen y estrategia

    Returns:
        Matriz actualizada
    """
    # Agrupar por (r√©gimen, estrategia)
    grouped = trade_history.groupby(['regime', 'strategy']).agg({
        'pnl_r': 'mean',
        'win_rate': 'mean',
        'sharpe': 'mean',
    })

    # Normalizar scores por r√©gimen
    fit_matrix = {}

    for regime in grouped.index.get_level_values('regime').unique():
        regime_data = grouped.loc[regime]

        # Normalizar sharpe a [0, 1]
        max_sharpe = regime_data['sharpe'].max()
        min_sharpe = regime_data['sharpe'].min()

        fit_scores = {}
        for strategy in regime_data.index:
            sharpe = regime_data.loc[strategy, 'sharpe']
            normalized = (sharpe - min_sharpe) / (max_sharpe - min_sharpe + 1e-6)
            fit_scores[strategy] = normalized

        fit_matrix[regime] = fit_scores

    return fit_matrix
```

2. Actualizar fit_matrix autom√°ticamente:
```python
# Ejecutar mensualmente
new_fit_matrix = recalibrate_regime_fit_matrix(trade_history_last_12_months)

# Validar cambios no son demasiado abruptos
validate_fit_matrix_changes(old_fit_matrix, new_fit_matrix, max_delta=0.15)

# Aplicar
update_brain_fit_matrix(new_fit_matrix)
```

**Impacto**: **Medio** ‚Äì Fit matrix se adapta a realidad de mercado.

**Prioridad**: **P1 ‚Äì MEDIA**

---

#### **Acci√≥n M3-007: Monitoreo continuo de modelos ML**

**Qu√© hacer**:
1. Implementar `src/monitoring/ml_model_monitor.py`:
```python
class MLModelMonitor:
    def __init__(self, model):
        self.model = model
        self.metrics_history = deque(maxlen=1000)

    def track_prediction(self, features, prediction, actual_outcome):
        """Registra predicci√≥n y outcome real."""
        self.metrics_history.append({
            'timestamp': datetime.now(),
            'prediction': prediction,
            'actual': actual_outcome,
            'correct': (prediction > 0.5) == (actual_outcome > 0),
        })

    def get_rolling_accuracy(self, window=100):
        """Accuracy en √∫ltimas N predicciones."""
        recent = list(self.metrics_history)[-window:]
        correct = sum(1 for m in recent if m['correct'])
        return correct / len(recent) if recent else 0.0

    def detect_degradation(self, baseline_accuracy=0.65, threshold=0.10):
        """Detecta si modelo se ha degradado."""
        current = self.get_rolling_accuracy()

        if current < baseline_accuracy * (1 - threshold):
            logger.critical(f"MODEL DEGRADATION: Accuracy {current:.3f} < {baseline_accuracy * (1 - threshold):.3f}")
            return True

        return False
```

2. Dashboard de m√©tricas:
   - Panel Grafana con:
     - Accuracy rolling 100 predicciones.
     - Precision/Recall.
     - Calibration plot.

**Impacto**: **Medio** ‚Äì Detecci√≥n temprana de degradaci√≥n.

**Prioridad**: **P1 ‚Äì MEDIA**

---

#### **Acci√≥n M3-008: Separar research/production en ML pipeline**

**Qu√© hacer**:
1. Estructura de directorios:
```
models/
  research/
    experiments/
      exp_001_randomforest/
        config.yaml
        model.pkl
        metrics.json
      exp_002_gradientboosting/
        ...
  validation/
    validated_models/
      v1.0_randomforest/
        model.pkl
        validation_report.md
  production/
    v1.2_randomforest/
      model.pkl
      deployment_date.txt
      performance_live.json
```

2. Proceso de promoci√≥n:
```
RESEARCH ‚Üí VALIDATION ‚Üí PRODUCTION

1. Research: Experimentar con modelos.
2. Validation: Backtest riguroso + out-of-sample.
3. Production: Deploy solo si pasa validaci√≥n.
```

3. Implementar versionado:
```python
# src/ml/model_registry.py
class ModelRegistry:
    def register_model(self, model, version, stage):
        """
        Registra modelo en registry.

        Args:
            model: Modelo entrenado
            version: e.g., 'v1.3'
            stage: 'RESEARCH', 'VALIDATION', 'PRODUCTION'
        """
        path = f"models/{stage.lower()}/{version}_model.pkl"
        pickle.dump(model, open(path, 'wb'))

        logger.info(f"Model {version} registered in stage {stage}")

    def promote_model(self, version, from_stage, to_stage):
        """Promociona modelo de stage a stage."""
        # Validar que cumple criterios
        if to_stage == 'PRODUCTION':
            assert self.validate_production_readiness(version)

        # Copiar modelo
        shutil.copy(f"models/{from_stage.lower()}/{version}_model.pkl",
                    f"models/{to_stage.lower()}/{version}_model.pkl")

        logger.info(f"Model {version} promoted: {from_stage} ‚Üí {to_stage}")
```

**Impacto**: **Medio** ‚Äì Previene modelos experimentales en producci√≥n.

**Prioridad**: **P1 ‚Äì MEDIA**

---

#### **Acci√≥n M3-009: Implementar circuit breaker para brain-layer**

**Qu√© hacer**:
1. Detectores de comportamiento an√≥malo:
```python
# src/safety/brain_circuit_breaker.py
class BrainCircuitBreaker:
    def check_rejection_rate(self, window_minutes=60):
        """Detecta si brain-layer rechaza demasiadas se√±ales."""
        recent_signals = get_signals_last_n_minutes(window_minutes)

        if not recent_signals:
            return True

        rejection_rate = sum(1 for s in recent_signals if not s['approved']) / len(recent_signals)

        if rejection_rate > 0.90:
            logger.critical(f"CIRCUIT BREAKER: Rejection rate {rejection_rate:.1%} > 90%")
            self.trigger_circuit_breaker("high_rejection_rate")
            return False

        return True

    def check_low_quality_approvals(self):
        """Detecta si brain-layer aprueba se√±ales de muy baja calidad."""
        recent_approvals = get_approved_signals_last_hour()

        low_quality_count = sum(1 for s in recent_approvals if s['quality_score'] < 0.30)

        if low_quality_count > 5:
            logger.critical(f"CIRCUIT BREAKER: {low_quality_count} low-quality signals approved")
            self.trigger_circuit_breaker("low_quality_approvals")
            return False

        return True

    def trigger_circuit_breaker(self, reason):
        """Activa circuit breaker y pasa a modo manual."""
        logger.critical(f"üö® CIRCUIT BREAKER TRIGGERED: {reason}")

        # Desactivar brain-layer
        set_brain_mode('MANUAL')

        # Enviar alerta
        send_alert(f"Brain-layer circuit breaker: {reason}")

        # Usar √∫ltimo snapshot bueno
        rollback_to_last_good_snapshot()
```

2. Ejecutar checks cada 5 minutos:
```python
# En main loop
if not brain_circuit_breaker.check_rejection_rate():
    # Brain-layer desactivado, usar configuraci√≥n manual
```

**Impacto**: **Medio-Alto** ‚Äì Previene da√±os por comportamiento an√≥malo.

**Prioridad**: **P1 ‚Äì ALTA**

---

#### **Acci√≥n M3-010: Limpiar comentarios y a√±adir docstrings**

**Qu√© hacer**:
1. Eliminar tono defensivo:
```python
# ANTES
"""
This is NOT a simple signal combiner. This is an advanced orchestration layer
that thinks at the PORTFOLIO level, not individual trade level.
"""

# DESPU√âS
"""
Brain-layer: Orchestrates signal selection and parameter optimization.

Implements institutional decision framework considering:
- Portfolio-level risk management
- Multi-timeframe coherence
- Regime-aware strategy selection
- ML-based continuous learning

Based on: Lo & MacKinlay (1997), L√≥pez de Prado (2018).
"""
```

2. A√±adir docstrings completos:
```python
def _score_signal(self, signal: Dict, market_context: Dict, regime: str) -> float:
    """
    Calcula score de se√±al usando modelo multi-factor institucional.

    Args:
        signal: Se√±al candidata con metadata y features
        market_context: Contexto de mercado actual (VPIN, OFI, depth, etc.)
        regime: R√©gimen de mercado identificado

    Returns:
        Score [0.0, 1.0] donde 1.0 = se√±al de m√°xima calidad

    Raises:
        ValueError: Si signal no contiene campos requeridos
    """
```

**Impacto**: **Bajo** ‚Äì Mejora profesionalismo.

**Prioridad**: **P2 ‚Äì BAJA**

---

### PLAN DE ACCI√ìN PRIORIZADO ‚Äì MANDATO 3

**Fase inmediata (Semana 1)**:
1. **M3-001**: Crear `BRAIN_LAYER_GOVERNANCE.md` con √°reas prohibidas.
2. **M3-002**: Implementar challenger model y validaci√≥n rigurosa.
3. **M3-003**: Rollback mechanism autom√°tico.
4. **M3-004**: Prevenir data leakage con time-series split estricto.

**Fase corto plazo (Semana 2-3)**:
5. **M3-005**: Calibrar pesos del arbitrator emp√≠ricamente.
6. **M3-006**: Actualizaci√≥n din√°mica de fit_matrix.
7. **M3-009**: Circuit breaker para brain-layer.

**Fase medio plazo (Mes 1)**:
8. **M3-007**: Monitoreo continuo de modelos ML.
9. **M3-008**: Separar research/production en ML pipeline.
10. **M3-010**: Limpiar comentarios y docstrings.

---

### VEREDICTO FINAL ‚Äì MANDATO 3

**Estado**: ‚ö†Ô∏è **CAJA NEGRA PELIGROSA SIN GOVERNANCE ‚Äì NO APTO PARA PRODUCCI√ìN**

**Logros**:
- ‚úÖ SignalArbitrator implementado con scoring multi-factor.
- ‚úÖ ML Adaptive Engine con learning loop.
- ‚úÖ Intento de formalizaci√≥n institucional.

**Fallas institucionales**:
- ‚ùå **Sin l√≠mites claros** ‚Üí brain-layer puede anular risk caps.
- ‚ùå **Sin challenger model** ‚Üí modelo ML no validado.
- ‚ùå **Sin rollback mechanism** ‚Üí ajustes malos son irreversibles.
- ‚ùå **Riesgo de data leakage** ‚Üí overfitting falso.
- ‚ùå **Pesos hardcoded sin justificaci√≥n** ‚Üí sub√≥ptimos.

**Recomendaci√≥n**:
**NO ACTIVAR BRAIN-LAYER EN PRODUCCI√ìN** hasta completar:
- M3-001 (Governance estricta).
- M3-002 (Challenger model).
- M3-003 (Rollback mechanism).
- M3-004 (Prevenir data leakage).
- M3-009 (Circuit breaker).

**Modo de operaci√≥n recomendado**:
- **Fase 1**: Brain-layer en **modo de observaci√≥n** (sugiere pero NO ejecuta).
- **Fase 2**: Brain-layer en **paper trading** (ejecuta en demo, NO en real).
- **Fase 3**: Brain-layer en **producci√≥n limitada** (solo arbitration, NO parameter tuning).
- **Fase 4**: Brain-layer en **producci√≥n completa** (tras 6 meses de validaci√≥n).

**Alternativa conservadora**:
- Usar brain-layer SOLO para signal arbitration (seleccionar entre conflictos).
- **Desactivar** ML Adaptive Engine hasta validaci√≥n completa.
- Ajustes de par√°metros 100% manuales con aprobaci√≥n humana.

---

**FIN AUDITOR√çA MANDATO 3**

---

## MANDATO 4 ‚Äì AUDITOR√çA INSTITUCIONAL: RISK ENGINE + QUALITY SCORE

**Alcance**: QualityScorer, StatisticalCircuitBreaker, InstitutionalRiskManager, position sizing, exposure controls, drawdown limits.

**Archivos analizados**:
- `src/core/risk_manager.py` (708 l√≠neas)
- `src/risk_management.py` (164 l√≠neas)
- `src/core/brain.py` (arbitration scoring)

**Fecha**: 2025-11-13
**Auditor**: Senior Quant Auditor (institucional)

---

### RIESGOS / DEBILIDADES DETECTADAS

#### P0 (CR√çTICO)

**P0-013: Quality Score con pesos hardcoded SIN calibraci√≥n emp√≠rica**

**Evidencia**:
```python
# risk_manager.py:38-44
self.weights = {
    'mtf_confluence': 0.40,
    'structure_alignment': 0.25,
    'order_flow': 0.20,
    'regime_fit': 0.10,
    'strategy_performance': 0.05,
}
```

**Problemas**:
- Pesos completamente arbitrarios (¬øpor qu√© MTF 40% y no 35%?)
- **NO existe documento** que justifique estos pesos con backtesting
- **NO hay validaci√≥n out-of-sample** de que estos pesos maximizan Sharpe o minimizan drawdown
- **NO hay mecanismo** de recalibraci√≥n peri√≥dica

**Impacto**:
- Quality Score es la columna vertebral del position sizing (0.33% ‚Üí 1.0% risk)
- Si los pesos est√°n mal, TODAS las posiciones est√°n mal dimensionadas
- P√©rdida potencial: **10-30% de rentabilidad anual** por mal sizing

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-014: Correlaciones de s√≠mbolos hardcoded SIN actualizaci√≥n din√°mica**

**Evidencia**:
```python
# risk_manager.py:565-573
correlations = {
    'EURUSD.pro_GBPUSD.pro': 0.85,
    'AUDUSD.pro_NZDUSD.pro': 0.92,
    'EURJPY.pro_GBPJPY.pro': 0.88,
    # ...
}
# Correlaciones est√°ticas desde... ¬øcu√°ndo?
```

**Problemas**:
- Correlaciones fijas, probablemente calculadas hace meses/a√±os
- **NO hay refresh peri√≥dico** (diario, semanal, mensual)
- **NO hay detecci√≥n de cambio de r√©gimen** de correlaci√≥n
- En crisis (2008, COVID, SVB 2023), correlaciones cambian radicalmente:
  - EURUSD-GBPUSD puede ir de 0.85 ‚Üí 0.30 en 48 horas
  - Oro-DXY puede invertir correlaci√≥n de -0.65 ‚Üí +0.40

**Impacto**:
- Exposure correlated check (l√≠nea 520-525) usa correlaciones incorrectas
- Puedes tener 10% exposure real cuando crees que tienes 5%
- En crisis: **riesgo de margin call** por correlaciones no detectadas

**Severidad**: **P0 ‚Äì CR√çTICO**

---

**P0-015: Exposure limits verifican >= permitiendo exceder l√≠mites**

**Evidencia**:
```python
# risk_manager.py:495
if total_exposure + proposed_risk_pct >= self.max_total_exposure_pct:
    return {'approved': False, ...}

# Problema: NO hay buffer de seguridad
# Si total = 5.9%, max = 6.0%, proposed = 0.5% ‚Üí OK
# Pero llega a 6.4% sin margen para slippage
```

**Problema**:
- Usa `>=` correctamente, pero permite exactamente el l√≠mite
- NO hay margen de seguridad para slippage, gap, volatilidad
- Institucional: si l√≠mite es 6%, parar en 5.4% (buffer 10%)

**Impacto**:
- Edge case: puede permitir posiciones que llevan exposure al l√≠mite exacto
- En volatilidad extrema (gap overnight), puede exceder l√≠mites reales

**Severidad**: **P0 ‚Äì CR√çTICO** (por falta de buffer)

---

**P0-016: Divisi√≥n por zero en position sizing (FIX fr√°gil)**

**Evidencia**:
```python
# risk_manager.py:459-463
denominator = (1.0 - self.min_quality_score)
if denominator == 0:
    base_size = self.max_risk_pct
else:
    base_size = self.min_risk_pct + (quality_score - self.min_quality_score) * \
               (self.max_risk_pct - self.min_risk_pct) / denominator
```

**Problema**:
- Si min_quality_score = 1.0 (configuraci√≥n err√≥nea), denominator = 0
- El c√≥digo tiene FIX, pero NO hay validaci√≥n de config al inicio
- ¬øPor qu√© permitir min_quality_score = 1.0 en primer lugar?

**Impacto**:
- Si pasa config inv√°lida, todas las posiciones ser√°n max_risk_pct (1.0%)
- NO detecta error hasta runtime

**Severidad**: **P0 ‚Äì CR√çTICO** (falta validaci√≥n de config)

---

#### P1 (IMPORTANTE)

**P1-013: Statistical Circuit Breaker con threshold arbitrario (z=2.5)**

**Evidencia**:
```python
# risk_manager.py:147
self.z_score_threshold = config.get('circuit_breaker_z_score', 2.5)  # 2.5œÉ = 99.4% confidence
```

**Problema**:
- z = 2.5 es threshold com√∫n en ciencia, pero **NO necesariamente √≥ptimo para trading**
- Permite p√©rdidas hasta 2.5 desviaciones est√°ndar (99.4% confidence)
- En estrategias de alta frecuencia, puede ser demasiado permisivo
- NO hay documento que justifique 2.5 vs 2.0 o 3.0

**Impacto**:
- Circuit breaker puede activarse demasiado tarde (despu√©s de -5% drawdown en vez de -3%)

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-014: Daily PnL reset con race condition potencial**

**Evidencia**:
```python
# risk_manager.py:675-679
from datetime import datetime
today = datetime.now().date()
if not hasattr(self, '_last_pnl_date') or self._last_pnl_date != today:
    self.daily_pnl = 0.0
    self._last_pnl_date = today
```

**Problema**:
- Si dos threads cierran posiciones exactamente a medianoche
- Thread A: lee _last_pnl_date = ayer, resetea
- Thread B: lee _last_pnl_date = hoy, NO resetea
- Resultado: daily_pnl puede acumular trades incorrectamente

**Impacto**:
- Daily loss limit (3%) puede no detectar p√©rdida real

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-015: Lot size calculation usa aproximaci√≥n (NO precisa)**

**Evidencia**:
```python
# risk_manager.py:624
lot_size = risk_amount / (stop_distance_pips * 10)  # Approximate
```

**Problema**:
- Comentario dice "Approximate"
- Valor de pip = $10 correcto para EURUSD 1 lote
- Pero **NO correcto** para XAUUSD, BTCUSD, √≠ndices

**Impacto**:
- Position sizing incorrecto para instrumentos no-forex
- Puede arriesgar 2% real cuando crees arriesgar 0.5%

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-016: NO validaci√≥n de stop_loss razonable**

**Evidencia**:
```python
# risk_manager.py:428-431
entry_price = signal['entry_price']
stop_loss = signal['stop_loss']
# NO valida si stop_loss es razonable
```

**Problema**:
- Acepta stop_loss sin verificar:
  - ¬øDemasiado cerca? (< 5 pips ‚Üí ruido)
  - ¬øDemasiado lejos? (> 500 pips ‚Üí irracional)
  - ¬øCoherente con ATR?

**Impacto**:
- Stop de 0.1 pips ‚Üí lot size gigante ‚Üí margin call
- Stop de 5000 pips ‚Üí lot size min√∫sculo

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

**P1-017: Strategy performance lookback fijo (30 trades) sin adaptaci√≥n temporal**

**Evidencia**:
```python
# risk_manager.py:60
self.strategy_performance: Dict[str, deque] = defaultdict(lambda: deque(maxlen=30))
```

**Problema**:
- Lookback de 30 trades fijo para TODAS las estrategias
- Estrategia A: 10 trades/d√≠a ‚Üí 3 d√≠as
- Estrategia B: 1 trade/semana ‚Üí 30 semanas!
- NO es comparable temporalmente

**Impacto**:
- Performance score sesgado entre estrategias de diferentes frecuencias

**Severidad**: **P1 ‚Äì IMPORTANTE**

---

#### P2 (MENOR)

**P2-010: Signal history con l√≠mite 1000 puede perder datos**

**Problema**: deque(maxlen=1000) pierde historia en alta frecuencia

**Severidad**: **P2**

---

**P2-011: Volatility regime adjustment con multiplicadores fijos**

**Problema**: Reducci√≥n 30% en HIGH vol, sin proporcionalidad a qu√© tan extrema es

**Severidad**: **P2**

---

**P2-012: NO logging de rechazos por quality score**

**Problema**: Se√±ales rechazadas NO se registran en logs

**Severidad**: **P2**

---

### RESUMEN DE RIESGOS

| Severidad | Cantidad | IDs |
|-----------|----------|-----|
| **P0 (Cr√≠tico)** | 4 | P0-013, P0-014, P0-015, P0-016 |
| **P1 (Importante)** | 5 | P1-013, P1-014, P1-015, P1-016, P1-017 |
| **P2 (Menor)** | 3 | P2-010, P2-011, P2-012 |
| **TOTAL** | **12** | |

---

### MEJORAS INSTITUCIONALES RECOMENDADAS

#### Acci√≥n M4-001: Calibraci√≥n emp√≠rica de Quality Score weights

**Qu√© hacer**: Optimizar pesos del Quality Score usando backtesting hist√≥rico para maximizar Sharpe ratio.

**C√≥digo ejemplo**:
```python
# research/quality_score_calibration.py
from scipy.optimize import minimize

def calibrate_quality_weights(historical_signals_df):
    """
    Calibra pesos usando time-series split optimization.

    Input: DataFrame con columnas:
      - mtf_confluence, structure_alignment, order_flow, regime_fit, strategy_performance
      - actual_pnl_R (resultado real del trade)
    """

    def objective(weights):
        # Calcular quality score con pesos propuestos
        quality = (signals['mtf_confluence'] * weights[0] +
                  signals['structure_alignment'] * weights[1] +
                  signals['order_flow'] * weights[2] +
                  signals['regime_fit'] * weights[3] +
                  signals['strategy_performance'] * weights[4])

        # Filtrar se√±ales quality > 0.60
        filtered = signals[quality >= 0.60]

        # Sharpe de se√±ales aceptadas
        sharpe = filtered['actual_pnl_R'].mean() / filtered['actual_pnl_R'].std() * np.sqrt(252)
        return -sharpe  # Minimizar negativo

    # Optimizar
    result = minimize(objective, [0.40, 0.25, 0.20, 0.10, 0.05],
                     method='SLSQP',
                     constraints=[{'type': 'eq', 'fun': lambda w: sum(w) - 1.0}],
                     bounds=[(0, 1)] * 5)

    return result.x
```

**Impacto**: +10-25% Sharpe ratio
**Esfuerzo**: 3-5 d√≠as
**Prioridad**: **P0**

---

#### Acci√≥n M4-002: Correlaciones din√°micas con rolling windows

**Qu√© hacer**: Calcular correlaciones diariamente con ventana rolling de 60 d√≠as.

**C√≥digo**:
```python
# src/core/dynamic_correlations.py
class DynamicCorrelationMonitor:
    def __init__(self, lookback_days=60):
        self.lookback_days = lookback_days
        self.price_history = {}

    def update_prices(self, symbol, price, timestamp):
        """Actualiza hist√≥rico de precios."""
        if symbol not in self.price_history:
            self.price_history[symbol] = pd.Series()

        self.price_history[symbol][timestamp] = price

        # Mantener solo lookback_days
        cutoff = timestamp - timedelta(days=self.lookback_days)
        self.price_history[symbol] = self.price_history[symbol][
            self.price_history[symbol].index >= cutoff
        ]

    def calculate_correlations(self):
        """Calcula matriz de correlaci√≥n rolling."""
        prices_df = pd.DataFrame(self.price_history)
        returns = prices_df.pct_change().dropna()
        return returns.corr()
```

**Impacto**: Reduce riesgo margin call en crisis
**Esfuerzo**: 2-3 d√≠as
**Prioridad**: **P0**

---

#### Acci√≥n M4-003: Exposure limits con buffer de seguridad

**Qu√© hacer**: Agregar buffer 10% a l√≠mites (si l√≠mite 6%, parar en 5.4%).

```python
# src/core/risk_manager.py
self.exposure_buffer_pct = 0.10  # 10% buffer

def _check_exposure_limits(self, signal, proposed_risk_pct):
    effective_limit = self.max_total_exposure_pct * (1.0 - self.exposure_buffer_pct)

    if total_exposure + proposed_risk_pct > effective_limit:
        return {'approved': False, 'reason': 'Exposure limit with buffer'}
```

**Impacto**: Margen de seguridad para slippage
**Esfuerzo**: 1 d√≠a
**Prioridad**: **P0**

---

#### Acci√≥n M4-004: Config validation al inicio

```python
# src/core/config_validator.py
class RiskConfigValidator:
    @staticmethod
    def validate(config):
        errors = []

        min_q = config.get('min_quality_score', 0.60)
        if min_q >= 1.0 or min_q < 0:
            errors.append(f"min_quality_score inv√°lido: {min_q}")

        if errors:
            raise ValueError(f"Config inv√°lida: {errors}")
```

**Impacto**: Previene crashes por config err√≥nea
**Esfuerzo**: 1 d√≠a
**Prioridad**: **P0**

---

#### Acci√≥n M4-005: Lot size calculation precisa por instrumento

**Qu√© hacer**: Usar specs de instrumento para c√°lculo exacto.

**Impacto**: Sizing preciso
**Esfuerzo**: 2 d√≠as
**Prioridad**: **P1**

---

#### Acci√≥n M4-006: Validaci√≥n de stop loss razonable

**Qu√© hacer**: Validar stop entre 1.0-5.0 ATR.

```python
def _validate_stop_loss(self, signal, market_context):
    atr = market_context['atr'][signal['symbol']]
    stop_distance = abs(signal['entry_price'] - signal['stop_loss'])
    stop_atr = stop_distance / atr

    if stop_atr < 1.0:
        return False, "Stop demasiado cerca (<1 ATR)"
    if stop_atr > 5.0:
        return False, "Stop demasiado lejos (>5 ATR)"

    return True, "OK"
```

**Impacto**: Previene bugs de estrategias
**Esfuerzo**: 1 d√≠a
**Prioridad**: **P1**

---

#### Acci√≥n M4-007: Strategy performance con lookback temporal

**Qu√© hacer**: Cambiar de 30 trades a 30 d√≠as.

**Impacto**: Performance score coherente
**Esfuerzo**: 1 d√≠a
**Prioridad**: **P1**

---

#### Acci√≥n M4-008: Logging de rechazos

**Qu√© hacer**: Log todas las se√±ales rechazadas para an√°lisis.

**Impacto**: Facilita debugging
**Esfuerzo**: 1 d√≠a
**Prioridad**: **P2**

---

#### Acci√≥n M4-009: Volatility adjustment proporcional

**Qu√© hacer**: Ajuste proporcional a vol_ratio (no fijo).

**Impacto**: Sizing m√°s fino en volatilidad extrema
**Esfuerzo**: 1 d√≠a
**Prioridad**: **P2**

---

#### Acci√≥n M4-010: Thread-safe daily PnL reset

**Qu√© hacer**: Usar threading.Lock para reset de daily_pnl.

**Impacto**: Previene race condition
**Esfuerzo**: 0.5 d√≠as
**Prioridad**: **P1**

---

### PLAN DE ACCI√ìN PRIORIZADO

#### FASE 1: Riesgos P0 (3-4 semanas)
- M4-001: Calibraci√≥n Quality Score (5 d√≠as)
- M4-002: Correlaciones din√°micas (3 d√≠as)
- M4-003: Exposure buffer (1 d√≠a)
- M4-004: Config validation (1 d√≠a)
- Testing (2 d√≠as)

#### FASE 2: Riesgos P1 (2 semanas)
- M4-005 a M4-007, M4-010 (5 d√≠as)
- Testing (2 d√≠as)

#### FASE 3: Mejoras P2 (1 semana)
- M4-008, M4-009 (2 d√≠as)
- Documentaci√≥n (1 d√≠a)

---

### VEREDICTO FINAL

**Estado**: ‚ö†Ô∏è **PARCIALMENTE APTO** para producci√≥n

**Logros**:
- ‚úÖ Statistical circuit breaker basado en SPC
- ‚úÖ Multi-factor quality scoring
- ‚úÖ Dynamic position sizing
- ‚úÖ Multi-dimensional exposure control
- ‚úÖ Fix de bugs cr√≠ticos (division by zero, exposure checks)

**Fallas cr√≠ticas**:
- ‚ùå **Quality Score SIN calibraci√≥n emp√≠rica** (P0-013)
- ‚ùå **Correlaciones hardcoded SIN actualizaci√≥n** (P0-014)
- ‚ùå **NO buffer de seguridad en exposure limits** (P0-015)
- ‚ùå **NO validaci√≥n de configuraci√≥n** (P0-016)

**Riesgo de producci√≥n SIN fixes**:
- Probabilidad **40%** de position sizing sub√≥ptimo (p√©rdida 10-25% Sharpe)
- Probabilidad **15%** de margin call en crisis
- Probabilidad **5%** de crash por config inv√°lida

**Recomendaci√≥n**:
1. **NO LANZAR** sin M4-001 (calibraci√≥n Quality Score)
2. **NO LANZAR** sin M4-002 (correlaciones din√°micas)
3. Implementar M4-003, M4-004 antes de producci√≥n

**Timeline para producci√≥n**: 4-6 semanas (FASES 1+2 completas)

**FIN AUDITOR√çA MANDATO 4**
